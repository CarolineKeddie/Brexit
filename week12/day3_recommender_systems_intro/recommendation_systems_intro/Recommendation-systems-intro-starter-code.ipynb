{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "\n",
    "# Recommendation Systems\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Lesson Guide<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Users-and-items\" data-toc-modified-id=\"Users-and-items-1\">Users and items</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-2\">Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#MAE-and-MSE\" data-toc-modified-id=\"MAE-and-MSE-2.1\">MAE and MSE</a></span></li><li><span><a href=\"#Correlations\" data-toc-modified-id=\"Correlations-2.2\">Correlations</a></span></li><li><span><a href=\"#Precision@k-and-recall@k\" data-toc-modified-id=\"Precision@k-and-recall@k-2.3\">Precision@k and recall@k</a></span></li><li><span><a href=\"#Inter-user-diversity\" data-toc-modified-id=\"Inter-user-diversity-2.4\">Inter-user diversity</a></span></li><li><span><a href=\"#Intra-user-diversity\" data-toc-modified-id=\"Intra-user-diversity-2.5\">Intra-user diversity</a></span></li><li><span><a href=\"#Novelty\" data-toc-modified-id=\"Novelty-2.6\">Novelty</a></span></li><li><span><a href=\"#Coverage\" data-toc-modified-id=\"Coverage-2.7\">Coverage</a></span></li></ul></li><li><span><a href=\"#Baseline-prediction\" data-toc-modified-id=\"Baseline-prediction-3\">Baseline prediction</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-3.0.1\">Example</a></span></li></ul></li></ul></li><li><span><a href=\"#Similarity-based-methods\" data-toc-modified-id=\"Similarity-based-methods-4\">Similarity based methods</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.0.1\">Example</a></span></li><li><span><a href=\"#What-would-be-the-baseline-for-each-user-item-pair?\" data-toc-modified-id=\"What-would-be-the-baseline-for-each-user-item-pair?-4.0.2\">What would be the baseline for each user-item pair?</a></span></li><li><span><a href=\"#Measure-the-user-and-product-similarity-using-the-different-measures-from-the-above.\" data-toc-modified-id=\"Measure-the-user-and-product-similarity-using-the-different-measures-from-the-above.-4.0.3\">Measure the user and product similarity using the different measures from the above.</a></span></li><li><span><a href=\"#Determine-the-top-3-items-for-each-user.\" data-toc-modified-id=\"Determine-the-top-3-items-for-each-user.-4.0.4\">Determine the top-3 items for each user.</a></span></li><li><span><a href=\"#Determine-the-inter-user-diversity.\" data-toc-modified-id=\"Determine-the-inter-user-diversity.-4.0.5\">Determine the inter-user diversity.</a></span></li><li><span><a href=\"#Determine-the-intra-user-diversity.\" data-toc-modified-id=\"Determine-the-intra-user-diversity.-4.0.6\">Determine the intra-user diversity.</a></span></li><li><span><a href=\"#Determine-the-novelty.\" data-toc-modified-id=\"Determine-the-novelty.-4.0.7\">Determine the novelty.</a></span></li></ul></li><li><span><a href=\"#KNN-with-means\" data-toc-modified-id=\"KNN-with-means-4.1\">KNN with means</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.1.1\">Example</a></span></li></ul></li><li><span><a href=\"#Slope-one-predictor\" data-toc-modified-id=\"Slope-one-predictor-4.2\">Slope-one predictor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example\" data-toc-modified-id=\"Example-4.2.1\">Example</a></span></li></ul></li></ul></li><li><span><a href=\"#Content-based-filtering\" data-toc-modified-id=\"Content-based-filtering-5\">Content based filtering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Singular-Value-decomposition\" data-toc-modified-id=\"Singular-Value-decomposition-5.1\">Singular Value decomposition</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-TruncatedSVD-to-reduce-the-dimensionality-of-the-rating-matrix.\" data-toc-modified-id=\"Use-TruncatedSVD-to-reduce-the-dimensionality-of-the-rating-matrix.-5.1.1\">Use <code>TruncatedSVD</code> to reduce the dimensionality of the rating matrix.</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation systems are of high relevance for many companies providing online content. Everybody has frequently to interact with such systems. In this lesson we want to understand how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try to recommend items to users, we face a few fundamental problems:\n",
    "\n",
    "1. Data Sparsity\n",
    "    - There are lots of products to recommend to many users. \n",
    "    - It is unlikely that a user will ever try out a large fraction of products.\n",
    "    - A few items are demanded by many users, but many only by a few.\n",
    "   \n",
    "- Cold Start\n",
    "    - We need to be able to give recommendations to users about which we only have scarse data (if at all).\n",
    "    \n",
    "- Accurate, but also diverse predictions\n",
    "    - We want to give useful recommendations in the sense that they match the user's preferences, but also that the recommendation contains some novelty for the user. \n",
    "\n",
    "- Evaluation\n",
    "    - Evaluation is difficult and might differ from algorithm to algorithm.\n",
    "\n",
    "- Scalability\n",
    "    - We need to be able to give recommendations on the spot even though there might be millions of users and items which we have to analyze carefully.\n",
    "\n",
    "- User interface\n",
    "    - Users want to know why they get particular recommendations.\n",
    "\n",
    "- Vulnerability to attacks\n",
    "    - We do not want our recommendation system to be abused for promoting or inhibiting particular items.\n",
    " \n",
    "- Temporal resolution\n",
    "    - Tastes and preferences do not remain the same over time. The algorithms that we will see neglect any kind of dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users and items\n",
    "\n",
    "In general we speak of users and items.\n",
    "\n",
    "> **Users:** indicate preferences for products through explicit/implicit ratings\n",
    "\n",
    "> **Items:** products which should be recommended and which have received ratings\n",
    "\n",
    "In most cases we are going to predict a certain rating for each possible pair of user and item. If the user already gave some rating we can compare it to our prediction:\n",
    "\n",
    "- True rating: $r_{ui}$\n",
    "- Predicted rating: $\\hat{r}_{ui}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE and MSE\n",
    "\n",
    "We can compare all existing ratings to our prediction for example using the root means squared error (RMSE) or the mean absolute error (MAE):\n",
    "\n",
    "    \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "{\\rm MAE} &=& \\frac{1}{|R|}\\sum_{(u,i)\\in R}|r_{ui}-{\\tilde r}_{ui}|\\\\\n",
    "{\\rm RMSE} &=& \\left(\\frac{1}{|R|}\\sum_{(u,i)\\in R}(r_{ui}-{\\tilde r}_{ui})^2\\right)^{1/2}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Here, $R$ stands for the set of all user-item pairs. $|\\cdot|$ indicates the cardinality of the set (here the number of user-item pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "\n",
    "Alternatively one can use correlations between true and predicted values for model evaluation, e.g.\n",
    "\n",
    "- the Pearson correlation\n",
    "- the Spearman rank correlation\n",
    "- Kendall's tau\n",
    "\n",
    "You can call these three for example with panda's `.corr()` function by setting the `method` argument.\n",
    "    \n",
    "The above scores are alright to obtain a model assessment if we have explicit ratings, but in the case of implicit ratings we might only be able to rank the items. In general, we would like to recommend the top-ranked items, but we have to evaluate if the top-ranked ones are really the ones relevant to the user, or if for some irrelevant items we predicted higher ratings.\n",
    "In that regard, we can use the usual classification metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision@k and recall@k\n",
    "\n",
    "Often users will not really care about all the rating predictions we are making, but instead they will have a major interest only in a few top-ranked items, let's say the $k$ top-ranked items. So it is appropriate to take only these $k$ ratings into account. We then ask how many of these $k$ items are relevant to the user. The relevance is in general difficult to measure, but we can for example ask how many out of the $k$ top-ranked items have a score beyond a certain threshold.\n",
    "\n",
    "We can then define the so-called precision@k and recall@k for $k$ recommended items:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "{\\rm precision@k} &=& \\frac{\\rm  Recommended\\ items\\ that\\ are\\ relevant}{\\rm Recommended\\ items}\\\\\n",
    "\\\\\n",
    "{\\rm recall@k} &=& \n",
    "\\frac{\\rm  Recommended\\ items\\ that\\ are\\ relevant}{\\rm Relevant\\ items}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Out of these scores we can define an F1@k score in the usual way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-user diversity\n",
    "\n",
    "We can compare how similar the recommendations are that we make for different users. We would like our recommender to make individual predictions based on user preferences, so predicting always the same top items would not be a good sign.\n",
    "\n",
    "We can measure the inter-user diversity by calculating the cosine-similarity between the $k$ top-ranked items and then average over all user pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-user diversity\n",
    "\n",
    "We can measure how similar the $k$ items are that we recommend to a particular user to obtain the intra-user diversity:\n",
    "\n",
    "$$\n",
    "I_u(k) = \\frac{1}{k(k-1)}\\sum_{i\\neq j}{\\rm sim}({\\rm item}_i,{\\rm item}_j)\n",
    "$$\n",
    "\n",
    "Averaging over all users gives the mean intra-similarity of the recommendation list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty\n",
    "\n",
    "We can measure the novelty of a recommendation by measuring how popular the recommended items are. For example we could take the degree of each item in the bipartite user-item network and average this degree over the recommendation list for each user before averaging these numbers over all users:\n",
    "\n",
    "$$\n",
    "{\\rm Novelty}(k) = \\frac{1}{M k}\\sum_{u=1}^{M}\\sum_{i\\ {\\rm in\\  top\\  k\\ of\\ u}} {\\rm degree}_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage\n",
    "\n",
    "Finally we can measure the so-called coverage, the fraction of all the distinct items $N_{\\rm distinct}$ that appear in all of our top-k recommendation lists:\n",
    "\n",
    "$$\n",
    "{\\rm Coverage}(k) = \\frac{N_{\\rm distinct}}{N}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline prediction\n",
    "\n",
    "As we are predicting ratings $\\hat{r}_{ui}$ of user $u$ on item $i$, the baseline should be the mean of all ratings, $\\mu$.\n",
    "\n",
    "As we will alway be considering a specific user or a specific item, we can determine how much each user's or item's rating is above the average. \n",
    "\n",
    "Therefore we add a bias term $b_u$ for each user and $b_i$ for each item, so that our baseline is\n",
    "\n",
    "$$\n",
    "{\\rm baseline}_{ui} = \\mu + b_u + b_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let's say for example that the average rating is $\\mu=3.52$, our user is very enthusiastic and on average evaluates items better than the average user by $b_u=0.3$, and the item is very popular receiving above average ratings with $b_i=0.5$. So we would have a baseline prediction of $4.32$.\n",
    "\n",
    "We will now look at various models which make more accurate predictions based on either similarity or content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity based methods\n",
    "\n",
    "In collaborative filtering, we use similarity measures to infer from past ratings what to recommend in the future. This can be \n",
    "\n",
    "- **item based:** a user who already rated some items positively would like to have similar items recommended in the future\n",
    "- **user based:** users who agree on their item ratings will do so also in the future\n",
    "\n",
    "The term collaborative filtering stems from the fact that multiple users have to share their data to obtain useful recommendations.\n",
    "\n",
    "\n",
    "We can use similarity measures we have already seen frequently:\n",
    "\n",
    "- **Pearson correlation:** \n",
    "    - The same as usual, but only user-item pairs will be taken into account that have been rated by both users (in the user based case) or users who have rated both items (in the item based case).\n",
    "\n",
    "- **Cosine similarity**\n",
    "\n",
    "$$\n",
    "{\\rm sim}_{\\cos}(u,v) = 1-\\frac{u\\cdot v}{\\|u\\|\\|v\\|}\n",
    "$$\n",
    "\n",
    "- **Mean squared difference**\n",
    "\n",
    "$$\n",
    "{\\rm msd}(u,v) = \\frac{1}{|I_{uv}|}\\sum_{i\\in I_{uv}}(r_{ui}-r_{vi})^2\n",
    "$$\n",
    "\n",
    "and then\n",
    "\n",
    "$$\n",
    "{\\rm msd\\_sim}(u,v) = \\frac{1}{{\\rm msd}(u,v)+1} \n",
    "$$\n",
    "\n",
    "and similarly for item pairs $i,j$. $|I_{uv}|$ is the number of items rated by both users $u$ and $v$.\n",
    "\n",
    "There exist many more based on the usual distance metrics, but also many specialized for recommendation system requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Consider the user-item matrix indicating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_0</th>\n",
       "      <th>item_1</th>\n",
       "      <th>item_2</th>\n",
       "      <th>item_3</th>\n",
       "      <th>item_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>4.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_2</th>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_0  item_1  item_2  item_3  item_4\n",
       "user_0     4.5     3.1     2.1     3.5     1.5\n",
       "user_1     4.2     2.8     3.2     1.8     2.1\n",
       "user_2     4.8     4.0     4.2     2.5     2.1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rui = pd.DataFrame([[4.5,3.1,2.1,3.5,1.5],\n",
    "                    [4.2,2.8,3.2,1.8,2.1],\n",
    "                    [4.8,4.0,4.2,2.5,2.1]],\n",
    "                    columns = [f'item_{i}' for i in range(5)],\n",
    "                    index = [f'user_{u}' for u in range(3)])\n",
    "rui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would be the baseline for each user-item pair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure the user and product similarity using the different measures from the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the top-3 items for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the inter-user diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the intra-user diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine the novelty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with means\n",
    "\n",
    "In the kNN with means model, we look at either the $k$ most similar users or items and predict\n",
    "\n",
    "- user similarity:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_u+\\frac{\\sum_{v \\in N_i^k(u)}{\\rm sim}(u,v)(r_{vi}-\\mu_v)}{\\sum_{v \\in N_i^k(u)}{\\rm sim}(u,v)}\n",
    "$$\n",
    "\n",
    "- item similarity:\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_i+\\frac{\\sum_{j \\in N_u^k(i)}{\\rm sim}(i,j)(r_{uj}-\\mu_j)}{\\sum_{j \\in N_u^k(i)}{\\rm sim}(i,j)}\n",
    "$$\n",
    "\n",
    "Here $N_i^k(u)$ denotes the $k$ most similar users to user $u$ who rated item $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "As an example, let's take user similarity measured by Pearson correlation and we consider the two nearest neighbors of user $1$.\n",
    "\n",
    "Let's say we have \n",
    "\n",
    "$\\mu_1 = 3$, $\\mu_2 = 2$, $\\mu_3 = 4$,\n",
    "${\\rm sim}(1,2)=0.8$, ${\\rm sim}(1,3)=0.5$, \n",
    "\n",
    "and want to predict for item 1 with \n",
    "\n",
    "$r_{21}=3.2$ and $r_{31}=3.8$.\n",
    "\n",
    "Then we obtain\n",
    "\n",
    "$$\n",
    "r_{11} = 3 +\\frac{0.8(3.2-2)+0.5(3.8-4)}{0.8+0.5}\n",
    "= 3+\\frac{0.8\\cdot1.2+0.5\\cdot(-0.2)}{1.3}\n",
    "\\approx 3.66\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope-one predictor\n",
    "\n",
    "\n",
    "This scheme makes use of both the information from other users who rated the same item and from the other items rated by the same user to predict a rating.\n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu_u + \\frac{1}{|R_i(u)|}\\sum_{j \\in R_i(u)}{\\rm dev}(i,j)\n",
    "$$\n",
    "\n",
    "where $R_i(u)$ is the set of items rated by user $u$\n",
    "and the average difference between the ratings of item $i$ and $j$ is\n",
    "\n",
    "$$\n",
    "{\\rm dev}(i,j) = \\frac{1}{|U_{ij}|}\\sum_{u\\in U_{ij}}(r_{ui}-r_{uj})\n",
    "$$\n",
    "\n",
    "and $U_{ij}$ is the set of all users that have rated both items $i$ and $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Consider the following example of ratings\n",
    "\n",
    "|         | item 1 | item 2|\n",
    "| ------- |:------:| -----:|\n",
    "| user 1  | 2      | 1.8   |\n",
    "| user 2  | 1      |  ?    |\n",
    "\n",
    "Then we have\n",
    "\n",
    "$\\mu_{\\rm user 2}=1$, $|U_{12}|=1$, $r_{11}=2$, $r_{12}=1.8$ and\n",
    "\n",
    "$$\n",
    "r_{22} = 1+\\frac{1}{1}(1.8-2) = 0.8\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content based filtering\n",
    "\n",
    "### Singular Value decomposition\n",
    "\n",
    "Remember principal component analysis for a data matrix $X$ of shape $n\\times p$. There we looked at the correlation matrix of the data and decomposed it into three matrices. After standard scaling the data matrix, this could be written as \n",
    "\n",
    "$$\n",
    "A = X^T X = V D V^T\n",
    "$$\n",
    "\n",
    "$A$ will be of shape $p\\times p$, $D$ will be a diagonal matrix with the eigenvalues of $A$ on the diagonal, and $V$ is the matrix of eigenvectors of $A$. As the correlation matrix $A$ is symmetric, the eigenvectors are pairwise orthogonal. This is known as the spectral theorem and helped us to decorrelate the data by transforming to the new coordinate system. This entails that the matrix $V^T$ is the inverse matrix of $V$. Such matrices are named orthogonal.\n",
    "\n",
    "Similarly we could have obtained a matrix\n",
    "\n",
    "$$\n",
    "B = X X^T = U^T D' U\n",
    "$$\n",
    "\n",
    "of shape $n\\times n$ with similar properties.\n",
    "\n",
    "This implies that each matrix (square or not, symmetric or not) can be written as a product of three matrices\n",
    "\n",
    "$$\n",
    "X = U \\Sigma V^T\n",
    "$$\n",
    "\n",
    "where $U$ is of shape $n\\times n$, $V$ is of shape $p\\times p$ and $\\Sigma$ of shape $n\\times p$ is a diagonal matrix with the so-called singular values on its diagonal (which are simply the square roots of the eigenvalues). Both $U$ and $V$ are orthogonal matrices.\n",
    "\n",
    "In the same way as for principal component analysis, we can reduce the dimensionality by restricting to the components with the $K$ largest singular values.\n",
    "\n",
    "This is what we are going to do with the user-item matrix. As it is very sparse anyway, we can expect that we won't loose too much information in this way and that we will somehow extract the main tastes and item attributes in this way.\n",
    "\n",
    "That is whereas the rating matrix can be exactly written as\n",
    "\n",
    "$$\n",
    "R = U\\Sigma V^T\n",
    "$$\n",
    "\n",
    "we can approximate it by choosing $\\Sigma$ of shape $K\\times K$ where $K<{\\rm min}(n,p)$ as\n",
    "\n",
    "$$\n",
    "\\hat{R} = U\\Sigma_K V^T\n",
    "$$\n",
    "\n",
    "Isolating global, user and item biases we can then write the rating prediction as \n",
    "\n",
    "$$\n",
    "\\hat{r}_{ui} = \\mu + b_u + b_i + \\sum_{k=1}^K p_{uk}q_{ki}\n",
    "$$\n",
    "\n",
    "Not restricting $K$ will lead to perfect predictions on the training set.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 3, 3],\n",
       "       [1, 2, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2,3],[1,3,3],[1,2,1]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.15142284, 0.        , 0.        ],\n",
       "       [0.        , 1.02970897, 0.        ],\n",
       "       [0.        , 0.        , 0.3157475 ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD with numpy\n",
    "\n",
    "U, S, VT = np.linalg.svd(A)\n",
    "Sigma = np.diag(S) # put the returned array S on the diagonal of a matrix\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 3., 3.],\n",
       "       [1., 2., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct the original matrix\n",
    "(U.dot(Sigma)).dot(VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83697452, 2.07128611, 2.99626008],\n",
       "       [1.20389433, 2.91084317, 3.00467747],\n",
       "       [0.87547428, 2.05445133, 0.9971433 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restrict to the 2 largest singular values\n",
    "U[:,:2].dot(Sigma[:2,:2]).dot(VT[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.69143694, -0.58448292],\n",
       "       [-4.3529303 ,  0.04953885],\n",
       "       [-2.29462286,  0.84630147]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the individual parts\n",
    "U[:,:2].dot(Sigma[:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2732291 , -0.66149335, -0.69840704],\n",
       "       [ 0.29365013,  0.63402177, -0.7153922 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.69143694, -0.58448292],\n",
       "       [ 4.3529303 ,  0.04953885],\n",
       "       [ 2.29462286,  0.84630147]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the same with sklearn\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd.fit_transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2732291 ,  0.66149335,  0.69840704],\n",
       "       [ 0.29365013,  0.63402177, -0.7153922 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83697452, 2.07128611, 2.99626008],\n",
       "       [1.20389433, 2.91084317, 3.00467747],\n",
       "       [0.87547428, 2.05445133, 0.9971433 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.fit_transform(A).dot(svd.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `TruncatedSVD` to reduce the dimensionality of the rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
