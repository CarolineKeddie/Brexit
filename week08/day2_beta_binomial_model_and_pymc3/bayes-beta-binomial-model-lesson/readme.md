<img src="http://imgur.com/1ZcRyrc.png" style="float: left; margin: 20px; height: 55px">

# Conjugacy and the Beta-Binomial Model

### Core

- Describe the concept of conjugate priors 
 - if we combine a given type of distribution for the likelihood function, we can choose a particular type of prior distribution and are guaranteed to get the same type for the posterior distribution)

- Describe what the binomial distribution models 
 - number of successes in n trials given the probability of success for each trial
 
- Understand that the maximum likelihood estimate (the MLE) for 'p' will be the fraction of successes observed in the data
- Describe what the beta distribution represents and where it fits into Bayes' formula
 - a distribution of probabilities here used as a prior

### Target

- Recall the probability mass function for the binomial distribution
- Recall the probability density function of the beta distribution
- Describe the difference between an informed and an uninformed prior

### Stretch

- Derive the maximum likelihood estimate (the MLE) for 'p' from the probability mass function for a binomial distribution
- Derive how we obtain a posterior beta distribution from a binomial likelihood function and a beta prior distribution

- [Research other pairs of conjugate priors](https://en.wikipedia.org/wiki/Conjugate_prior)
