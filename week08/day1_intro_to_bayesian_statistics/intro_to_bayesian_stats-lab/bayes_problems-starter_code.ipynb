{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Additional Bayesian statistics problems\n",
    "\n",
    "_Instructor: Aymeric Flaisler_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. German Tank Problem\n",
    "\n",
    "A railroad numbers its railcars $1,\\ldots,N$. You see a railcar with the number 60 painted on it. The problem is to come up with an estimate for $N$. We'll denote $N=\\theta$ to stick with our standard notation.\n",
    "\n",
    "Apply Bayesian analysis to this problem by articulating the hypothesis/hypotheses, the data, and the likelihood. Be sure to try at least three separate prior distributions for $\\theta$. What effect does this have on your posterior distribution of $\\theta$ and, thus, your estimate for $N$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n",
    "\n",
    "## The hypotheses are:\n",
    "## H_60: N = 60.\n",
    "## H_61: N = 61.\n",
    "## H_62: N = 62.\n",
    "## ...\n",
    "## H_1000: N = 1,000. (I arbitrarily stop here, but we could add more hypotheses.)\n",
    "\n",
    "## The data is: we observed railcar 60.\n",
    "\n",
    "## What is the likelihood P(y=60|H) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â Now let's says that N = 100\n",
    "## What is the prior?\n",
    "\n",
    "## Try to plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write out the formula for this:\n",
    "\n",
    "#### $$ P(\\text{total trains} = N \\;|\\; \\text{observed} = x) = \\frac{P(\\text{observed} = x \\;|\\; \\text{total trains} = N)}{P(\\text{observed} = x)} P(\\text{total trains} = N) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the prior, P(total trains = N). We believe that the total number of trains \n",
    "# can only be between 1 and 100 and that any of those are equally likely.\n",
    "\n",
    "# We can write out now a function for the likelihood:\n",
    "# P(observed = x | total trains = N)\n",
    "\n",
    "\n",
    "# This will take three arguments: which train number was observed and how many trains\n",
    "# there are (the conditional part total trains = N)\n",
    "\n",
    "def likelihood(observed, total_trains):\n",
    "    if observed > total_trains:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return 1./total_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all of our hypotheses and calculate the likelihood. Because this is a discrete\n",
    "# problem we can plug in each of our train numbers that we have a prior for to get out\n",
    "# the corresponding likelihood:\n",
    "\n",
    "for x in range(len(prior)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will multiply the prior by the likelihood at this point to get our likelihood\n",
    "# adjusted by our prior belief:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see these probabilities are tiny - and they don't sum to 1...\n",
    "\n",
    "# This is where the denominator - the marginal probability of observing train 60\n",
    "# comes into play. It will normalize this distribution so that the values sum to 1\n",
    "# and form a proper probability distribution.\n",
    "\n",
    "# In the Monty Hall problem, we could have calculated the denominator (the marginal \n",
    "# probability that Monty opens door B) as:\n",
    "# P(opened = B) = P(opened=B|win=A)P(win=A) + P(opened=B|win=B)P(win=B) + P(opened=B|win=C)P(win=C)\n",
    "\n",
    "# In order to find the marginal probability we sum the probabilities across all our hypotheses.\n",
    "# This is from the law of total probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write out the marginal probability of observing train 60 with the law of total probability formula.\n",
    "\n",
    "### $$ P(\\text{observed} = 60) = \\sum_{i=1}^{100} P(\\text{observed} = 60 \\cap \\text{total trains} = i) $$\n",
    "\n",
    "Which can be re-written as:\n",
    "\n",
    "### $$ P(\\text{observed} = 60) = \\sum_{i=1}^{100} P(\\text{observed} = 60 \\;|\\; \\text{total trains} = i)P(\\text{total_trains} = i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the denominator here, our marginal probability of observing train 60, is the sum\n",
    "# of our likelihoods times priors for all hypotheses about the train.\n",
    "\n",
    "# If we think about this from a purely numerical standpoint - this has to be the case because\n",
    "# in order for all of our likelihood*prior values to sum to 1. and form a proper probability \n",
    "# distribution, we will need to divide them by their sum.\n",
    "\n",
    "posteriors = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dungeons & Dragons Dice Problem #1\n",
    "\n",
    "There are five dice: a 4-sided die, 6-sided die, 8-sided die, 12-sided die, 20-sided die. You roll a 6. The problem is to predict which die was thrown.\n",
    "\n",
    "Apply Bayesian analysis to this problem by articulating the hypothesis/hypotheses, the data, and the likelihood. Identify which die you believe to be the thrown die and how likely this is to be the thrown die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dungeons & Dragons Dice Problem #2\n",
    "\n",
    "There are five dice: a 4-sided die, 6-sided die, 8-sided die, 12-sided die, 20-sided die. You roll the same die and get a 6, 4, 8, 7, 5, 7. The problem is to predict which die was thrown.\n",
    "\n",
    "Apply Bayesian analysis to this problem by articulating the hypothesis/hypotheses, the data, and the likelihood. Identify which die you believe to be the thrown die and how likely this is to be the thrown die."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. M&M Problem\n",
    "\n",
    "You have two bags of M&Ms. The first bag, created before 1995, has the following color distribution: 30% brown, 20% yellow, 20% red, 10% orange, 10% green, 10% tan. The second bag, created after 1995, has the following color distribution: 24% blue, 20% green, 16% orange, 14% yellow, 12% red, 12% brown.\n",
    "\n",
    "From one bag, you pull a yellow M&M. The problem is to predict from which bag you pulled the yellow M&M.\n",
    "\n",
    "Apply Bayesian analysis to this problem by articulating the hypothesis/hypotheses, the data, the likelihood.\n",
    "\n",
    "Consider the yellow M&M already pulled (so this is part of your data). From the other bag, you pull a green M&M. Update your posterior appropriately and update your answer to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
