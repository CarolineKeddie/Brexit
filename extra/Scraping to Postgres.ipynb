{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example Scraping to Local Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First we will need to create a database in our terminal\n",
    "\n",
    "type `psql` to get into the postgres shell\n",
    "\n",
    "Then type: `CREATE DATABASE capstone_scrape;` - this should return a string saying CREATE DATABASE. You now have the database created, now you have something to connect to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#imports & Settings\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import psycopg2\n",
    "config = {'host':\"localhost\",'database':\"capstone_scrape\", 'user':\"Tim\", 'password':\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We then need to define a table in the database, and define what the table is going to hold. It's important that before this stage you have understood your source data and what you want to store in your database - you don't want to have to change the scema later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### CREATE TABLEs IN DATABASE EXAMLPE\n",
    "\n",
    "def create_table(database):\n",
    "    \"\"\"\n",
    "    USE WITH CAUTION - DEMO (NOT FOR PRODUCTION)\n",
    "    Checks if a table exists in Database, DROPS it, and then creates table in the PostgreSQL database\n",
    "    \"\"\"\n",
    "    commands = (\n",
    "        \"\"\"\n",
    "        DROP TABLE IF EXISTS scrape\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        CREATE TABLE scrape (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            url VARCHAR(255) NOT NULL,\n",
    "            visited VARCHAR(255) NOT NULL,\n",
    "            title VARCHAR(255) NOT NULL\n",
    "            )       \n",
    "        \"\"\")\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        conn = psycopg2.connect(host=\"localhost\",database=database, user=\"Tim\", password=\"\")\n",
    "        cur = conn.cursor()\n",
    "        # Drop if exists then add table\n",
    "        for command in commands:\n",
    "            cur.execute(command)\n",
    "        # close communication with the PostgreSQL database server\n",
    "        cur.close()\n",
    "        # commit the changes\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "create_table(\"capstone_scrape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def insert_data(url,visited,title):\n",
    "    \"\"\" \n",
    "    CLASSROOM EXAMPLE - NOT PRODUCTION TESTED\n",
    "    \n",
    "    insert a new info into the scrape table \"\"\"\n",
    "    sql = \"\"\"INSERT INTO scrape (url, visited, title) VALUES(%s, %s, %s) RETURNING id;\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL database\n",
    "        conn = psycopg2.connect(host=\"localhost\",database=\"capstone_scrape\", user=\"Tim\", password=\"\")\n",
    "        # create a new cursor\n",
    "        cur = conn.cursor()\n",
    "        # execute the INSERT statement\n",
    "        data = (url,visited,title)\n",
    "        cur.execute(sql, data)\n",
    "        # get the generated id back\n",
    "        tbl_id = cur.fetchone()[0]\n",
    "        # commit the changes to the database\n",
    "        conn.commit()\n",
    "        # close communication with the database\n",
    "        cur.close()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "    return tbl_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Example of an individual scraping element \n",
    "# you will need lots of these helper functions- one for each element you want to store\n",
    "# Its important that each function returns the object type that the database is expecting\n",
    "\n",
    "def extract_title_from_soup(soup):\n",
    "    title = soup.title.string\n",
    "    if title == \"\":\n",
    "        return \"No Title\"\n",
    "    else:\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "urls = [\"http://www.techcrunch.com\",\"http://news.ycombinator.com\",\"http://www.ft.com\"]\n",
    "\n",
    "problem_urls = []\n",
    "\n",
    "for url in urls:\n",
    "    try:                                               # try the below\n",
    "        r = requests.get(url)                          # Get the Page\n",
    "        soup = BeautifulSoup(r.text,'html.parser')     # Parse the page with Beautiful Soup\n",
    "        title = extract_title_from_soup(soup)          # Call the function to extract the title from the page \n",
    "        save = insert_data(url,1,title)                 # Call the function to save the data into our DB\n",
    "        if type (save) != int:                         # if our save function returns an error (not integer) store url\n",
    "            problem_urls.append(url)\n",
    "    except:                                            # for any error above store the url taht caused a problem\n",
    "        problem_urls.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspecting The Results of your Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://localhost:5432/capstone_scrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>visited</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.techcrunch.com</td>\n",
       "      <td>1</td>\n",
       "      <td>TechCrunch – Startup and Technology News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://news.ycombinator.com</td>\n",
       "      <td>1</td>\n",
       "      <td>Hacker News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>http://www.ft.com</td>\n",
       "      <td>1</td>\n",
       "      <td>Financial Times</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                          url visited  \\\n",
       "0   1    http://www.techcrunch.com       1   \n",
       "1   2  http://news.ycombinator.com       1   \n",
       "2   3            http://www.ft.com       1   \n",
       "\n",
       "                                      title  \n",
       "0  TechCrunch – Startup and Technology News  \n",
       "1                               Hacker News  \n",
       "2                           Financial Times  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT * FROM scrape\", con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clear the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"DELETE FROM scrape\n",
    "WHERE id > 0;\"\"\"\n",
    "\n",
    "conn = psycopg2.connect(host=\"localhost\",database=\"capstone_scrape\", user=\"Tim\", password=\"\")\n",
    "# create a new cursor\n",
    "cur = conn.cursor()\n",
    "# execute the INSERT statement\n",
    "# data = (url,visited)\n",
    "cur.execute(sql)\n",
    "# get the generated id back\n",
    "# url0 = cur.fetchone()[0]\n",
    "# commit the changes to the database\n",
    "conn.commit()\n",
    "# close communication with the database\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
