{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Evaluating SVM on Multiple Datasets\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you can explore several datasets with SVM classifiers compared to logistic regression and kNN classifiers. \n",
    "\n",
    "Your datasets folder has these four datasets to choose from for the lab:\n",
    "\n",
    "**Breast cancer**\n",
    "\n",
    "    resource-datasets/breast_cancer_wisconsin\n",
    "\n",
    "**Spambase**\n",
    "\n",
    "    resource-datasets/spam\n",
    "\n",
    "**Car evaluation**\n",
    "\n",
    "    resource-datasets/car_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A: Breast cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and prepare the data\n",
    "\n",
    "- Are there any missing values? Impute or clean if so.\n",
    "- Select a classification target and predictors.\n",
    "- Determine the baseline for accuracy.\n",
    "- Rescale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "X = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "y = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.627417\n",
       "0    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline => 65%\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build an SVM classifier on the data\n",
    "\n",
    "For details on the SVM classifier, see [SVM-classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
    "\n",
    "- Initialize and train a linear SVM with the default settings. What is the average accuracy score with 5-fold cross validation?\n",
    "- Repeat using a radial basis function (rbf) classifier. Compare the scores. Which one is better?\n",
    "- Print the confusion matrix and classification report for your models.\n",
    "\n",
    "- [Classification report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "\n",
    "- Confusion matrix:\n",
    "\n",
    " ```python\n",
    "df_confusion = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, X_train, y_train, X_test, y_test, cv=5):\n",
    "    model.fit(X_train,y_train)\n",
    "    scores_train = cross_val_score(model, X_train, y_train, cv=cv)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    sm = scores_train.mean()\n",
    "    print(\"Average training score: {:0.3}\".format(sm))\n",
    "    print(\"Test score: {:0.3}\".format(model.score(X_test, y_test)))\n",
    "    return predictions_test\n",
    "\n",
    "\n",
    "def print_cm_cr(y_true, y_pred):\n",
    "    \"\"\"prints the confusion matrix and the classification report\"\"\"\n",
    "    confusion = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=[\n",
    "                            'Predicted'], margins=True)\n",
    "    print(confusion)\n",
    "    print()\n",
    "    print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LinearSVC(loss='hinge')\n",
    "model_2 = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868131868131869"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train,y_train)\n",
    "model_1.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868131868131869"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train,y_train)\n",
    "model_2.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin = LinearSVC()\n",
    "model_rbf = SVC(kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training score: 0.969\n",
      "Test score: 0.956\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          40   2   42\n",
      "1           3  69   72\n",
      "All        43  71  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94        42\n",
      "          1       0.97      0.96      0.97        72\n",
      "\n",
      "avg / total       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = get_accuracy(model_lin, X_train, y_train, X_test, y_test, cv=5);\n",
    "print_cm_cr(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training score: 0.969\n",
      "Test score: 0.965\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          39   3   42\n",
      "1           1  71   72\n",
      "All        40  74  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.93      0.95        42\n",
      "          1       0.96      0.99      0.97        72\n",
      "\n",
      "avg / total       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = get_accuracy(model_rbf, X_train, y_train, X_test, y_test, cv=5);\n",
    "print_cm_cr(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tune the SVM classifiers with gridsearch\n",
    "\n",
    "- Check in the documentation which parameters can be tuned in combination with different kernels.\n",
    "- Create a further train-test split to obtain a hold-out validation set.\n",
    "- Cross-validate scores.\n",
    "- Examine confusion matrices and classification reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_func(estimator, params, X_train, y_train, X_test, y_test, scoring_function=metrics.accuracy_score, scoring='accuracy'):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=params,\n",
    "        return_train_score=True,\n",
    "        scoring=scoring)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best score\")\n",
    "    print(gs.best_score_)\n",
    "    print()\n",
    "    print(\"Best estimator\")\n",
    "    print(gs.best_estimator_.get_params())\n",
    "    print()\n",
    "\n",
    "    predictions = gs.best_estimator_.predict(X_test)\n",
    "    print('Test score: ', scoring_function(y_test, predictions))\n",
    "    print()\n",
    "    print_cm_cr(y_test, predictions)\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9802197802197802\n",
      "\n",
      "Best estimator\n",
      "{'C': 0.01, 'class_weight': None, 'dual': True, 'fit_intercept': False, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Test score:  0.9824561403508771\n",
      "\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          42   0   42\n",
      "1           2  70   72\n",
      "All        44  70  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        42\n",
      "          1       1.00      0.97      0.99        72\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_lin = {'C': np.logspace(-10, 10, 21),\n",
    "              'fit_intercept': [True, False]}\n",
    "gs_lin = grid_search_func(model_lin, params_lin,\n",
    "                          X_train, y_train, X_test, y_test,\n",
    "                          scoring_function=metrics.accuracy_score,\n",
    "                          scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.967032967032967\n",
      "\n",
      "Best estimator\n",
      "{'C': 1.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Test score:  0.956140350877193\n",
      "\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          38   4   42\n",
      "1           1  71   72\n",
      "All        39  75  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.90      0.94        42\n",
      "          1       0.95      0.99      0.97        72\n",
      "\n",
      "avg / total       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_rbf = {'C': np.logspace(-10, 10, 21),\n",
    "          'gamma':np.linspace(0.01,2,20)}\n",
    "gs_rbf = grid_search_func(model_rbf,params_rbf,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare kNN and logistic regression on the dataset.\n",
    "\n",
    "\n",
    "- Gridsearch optimal parameters \n",
    "- Cross-validate scores.\n",
    "- Examine confusion matrices and classification reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9648351648351648\n",
      "\n",
      "Best estimator\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': 1, 'n_neighbors': 4, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Test score:  0.9824561403508771\n",
      "\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          41   1   42\n",
      "1           1  71   72\n",
      "All        42  72  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        42\n",
      "          1       0.99      0.99      0.99        72\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors':list(range(1,21,3)),\n",
    "    'weights':['distance','uniform']\n",
    "}\n",
    "\n",
    "gs_knn = grid_search_func(model_knn,params_knn,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9758241758241758\n",
      "\n",
      "Best estimator\n",
      "{'C': 0.06951927961775606, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Test score:  0.9824561403508771\n",
      "\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          41   1   42\n",
      "1           1  71   72\n",
      "All        42  72  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98        42\n",
      "          1       0.99      0.99      0.99        72\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "params_lr = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-4, 2, 20),\n",
    "    'solver':['liblinear']\n",
    "}\n",
    "gs_lr = grid_search_func(model_lr,params_lr,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Consider different scores in the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9791781371549413\n",
      "\n",
      "Best estimator\n",
      "{'C': 0.01, 'class_weight': None, 'dual': True, 'fit_intercept': False, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Test score:  1.0\n",
      "\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          42   0   42\n",
      "1           2  70   72\n",
      "All        44  70  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        42\n",
      "          1       1.00      0.97      0.99        72\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lin_pr = grid_search_func(model_lin, params_lin,\n",
    "                          X_train, y_train, X_test, y_test,\n",
    "                          scoring_function=metrics.precision_score,\n",
    "                          scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9791781371549413\n",
      "\n",
      "Best estimator\n",
      "{'C': 0.01, 'class_weight': None, 'dual': True, 'fit_intercept': False, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Test score:  1.0\n",
      "\n",
      "Predicted   0   1  All\n",
      "Actual                \n",
      "0          42   0   42\n",
      "1           2  70   72\n",
      "All        44  70  114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.98        42\n",
      "          1       1.00      0.97      0.99        72\n",
      "\n",
      "avg / total       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf_pr = grid_search_func(model_lin, params_lin,\n",
    "                          X_train, y_train, X_test, y_test,\n",
    "                          scoring_function=metrics.precision_score,\n",
    "                          scoring='precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B: Car data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = pd.read_csv('../../../../../resource-datasets/car_evaluation/car.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>acceptability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety acceptability\n",
       "0  vhigh  vhigh     2       2    small    low         unacc\n",
       "1  vhigh  vhigh     2       2    small    med         unacc\n",
       "2  vhigh  vhigh     2       2    small   high         unacc"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vhigh', 'high', 'med', 'low'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.buying.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['vhigh', 'high', 'med', 'low'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.maint.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['small', 'med', 'big'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.lug_boot.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['low', 'med', 'high'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.safety.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.acceptability.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying           0\n",
       "maint            0\n",
       "doors            0\n",
       "persons          0\n",
       "lug_boot         0\n",
       "safety           0\n",
       "acceptability    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any na?\n",
    "car.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = car.acceptability.map(lambda x: 1 if x in ['vgood','good'] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [col for col in car.columns if col!='acceptability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(car,columns=categorical,drop_first=True)\n",
    "X.drop('acceptability',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "      <th>doors_3</th>\n",
       "      <th>doors_4</th>\n",
       "      <th>doors_5more</th>\n",
       "      <th>persons_4</th>\n",
       "      <th>persons_more</th>\n",
       "      <th>lug_boot_med</th>\n",
       "      <th>lug_boot_small</th>\n",
       "      <th>safety_low</th>\n",
       "      <th>safety_med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_low  buying_med  buying_vhigh  maint_low  maint_med  maint_vhigh  \\\n",
       "0           0           0             1          0          0            1   \n",
       "1           0           0             1          0          0            1   \n",
       "2           0           0             1          0          0            1   \n",
       "3           0           0             1          0          0            1   \n",
       "4           0           0             1          0          0            1   \n",
       "\n",
       "   doors_3  doors_4  doors_5more  persons_4  persons_more  lug_boot_med  \\\n",
       "0        0        0            0          0             0             0   \n",
       "1        0        0            0          0             0             0   \n",
       "2        0        0            0          0             0             0   \n",
       "3        0        0            0          0             0             1   \n",
       "4        0        0            0          0             0             1   \n",
       "\n",
       "   lug_boot_small  safety_low  safety_med  \n",
       "0               1           1           0  \n",
       "1               1           0           1  \n",
       "2               1           0           0  \n",
       "3               0           1           0  \n",
       "4               0           0           1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.922454\n",
       "1    0.077546\n",
       "Name: acceptability, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)\n",
    "# baseline is 92.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build an SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train),columns=X.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test),columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training score: 0.986\n",
      "Test score: 0.986\n",
      "Predicted    0   1  All\n",
      "Actual                 \n",
      "0          317   2  319\n",
      "1            3  24   27\n",
      "All        320  26  346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       319\n",
      "          1       0.92      0.89      0.91        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = get_accuracy(model_lin, X_train, y_train, X_test, y_test, cv=5);\n",
    "print_cm_cr(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training score: 0.97\n",
      "Test score: 0.968\n",
      "Predicted    0   1  All\n",
      "Actual                 \n",
      "0          317   2  319\n",
      "1            9  18   27\n",
      "All        326  20  346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98       319\n",
      "          1       0.90      0.67      0.77        27\n",
      "\n",
      "avg / total       0.97      0.97      0.97       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = get_accuracy(model_rbf, X_train, y_train, X_test, y_test, cv=5);\n",
    "print_cm_cr(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grid search SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9898697539797395\n",
      "\n",
      "Best estimator\n",
      "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Test score:  0.9855491329479769\n",
      "\n",
      "Predicted    0   1  All\n",
      "Actual                 \n",
      "0          317   2  319\n",
      "1            3  24   27\n",
      "All        320  26  346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       319\n",
      "          1       0.92      0.89      0.91        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lin = grid_search_func(model_lin,params_lin,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9985528219971056\n",
      "\n",
      "Best estimator\n",
      "{'C': 1000.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Test score:  0.9971098265895953\n",
      "\n",
      "Predicted    0   1  All\n",
      "Actual                 \n",
      "0          319   0  319\n",
      "1            1  26   27\n",
      "All        320  26  346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       319\n",
      "          1       1.00      0.96      0.98        27\n",
      "\n",
      "avg / total       1.00      1.00      1.00       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf = grid_search_func(model_rbf,params_rbf,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare with kNN and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9319826338639653\n",
      "\n",
      "Best estimator\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': 1, 'n_neighbors': 7, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Test score:  0.9335260115606936\n",
      "\n",
      "Predicted    0  1  All\n",
      "Actual                \n",
      "0          318  1  319\n",
      "1           22  5   27\n",
      "All        340  6  346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97       319\n",
      "          1       0.83      0.19      0.30        27\n",
      "\n",
      "avg / total       0.93      0.93      0.91       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_knn = grid_search_func(model_knn,params_knn,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9905933429811867\n",
      "\n",
      "Best estimator\n",
      "{'C': 1.2742749857031321, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l1', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Test score:  0.9855491329479769\n",
      "\n",
      "Predicted    0   1  All\n",
      "Actual                 \n",
      "0          318   1  319\n",
      "1            4  23   27\n",
      "All        322  24  346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       319\n",
      "          1       0.96      0.85      0.90        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lr = grid_search_func(model_lr,params_lr,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C: Spam data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...    char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...           0.00        0.000   \n",
       "1             0.00            0.94  ...           0.00        0.132   \n",
       "2             0.64            0.25  ...           0.01        0.143   \n",
       "3             0.31            0.63  ...           0.00        0.137   \n",
       "4             0.31            0.63  ...           0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv('../../../../../resource-datasets/spam/spambase.csv')\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n",
      "0.6059552271245381\n"
     ]
    }
   ],
   "source": [
    "print(spam.shape)\n",
    "print(1-spam['class'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = spam['class']\n",
    "X = spam.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build an SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training score: 0.925\n",
      "Test score: 0.916\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0          523   35  558\n",
      "1           42  321  363\n",
      "All        565  356  921\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.94      0.93       558\n",
      "          1       0.90      0.88      0.89       363\n",
      "\n",
      "avg / total       0.92      0.92      0.92       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = get_accuracy(model_lin, X_train, y_train, X_test, y_test, cv=5);\n",
    "print_cm_cr(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training score: 0.93\n",
      "Test score: 0.934\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0          537   21  558\n",
      "1           40  323  363\n",
      "All        577  344  921\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95       558\n",
      "          1       0.94      0.89      0.91       363\n",
      "\n",
      "avg / total       0.93      0.93      0.93       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = get_accuracy(model_rbf, X_train, y_train, X_test, y_test, cv=5);\n",
    "print_cm_cr(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grid search SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9239130434782609\n",
      "\n",
      "Best estimator\n",
      "{'C': 10.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Test score:  0.9196525515743756\n",
      "\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0          524   34  558\n",
      "1           40  323  363\n",
      "All        564  357  921\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.94      0.93       558\n",
      "          1       0.90      0.89      0.90       363\n",
      "\n",
      "avg / total       0.92      0.92      0.92       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_lin = grid_search_func(model_lin,params_lin,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9290760869565218\n",
      "\n",
      "Best estimator\n",
      "{'C': 10.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Test score:  0.9348534201954397\n",
      "\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0          536   22  558\n",
      "1           38  325  363\n",
      "All        574  347  921\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95       558\n",
      "          1       0.94      0.90      0.92       363\n",
      "\n",
      "avg / total       0.93      0.93      0.93       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs_rbf = grid_search_func(model_rbf,params_rbf,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare to kNN and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score\n",
      "0.9141304347826087\n",
      "\n",
      "Best estimator\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': 1, 'n_neighbors': 10, 'p': 2, 'weights': 'distance'}\n",
      "\n",
      "Test score:  0.9131378935939196\n",
      "\n",
      "Predicted    0    1  All\n",
      "Actual                  \n",
      "0          526   32  558\n",
      "1           48  315  363\n",
      "All        574  347  921\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93       558\n",
      "          1       0.91      0.87      0.89       363\n",
      "\n",
      "avg / total       0.91      0.91      0.91       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors':list(range(1,21,3)),\n",
    "    'weights':['distance','uniform']\n",
    "}\n",
    "\n",
    "gs_knn = grid_search_func(model_knn,params_knn,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()\n",
    "params_lr = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'C':np.logspace(-4, 2, 20),\n",
    "    'solver':['liblinear']\n",
    "}\n",
    "gs_lr = grid_search_func(model_lr,params_lr,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "253px",
    "left": "0px",
    "right": "571.857px",
    "top": "146px",
    "width": "159px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
