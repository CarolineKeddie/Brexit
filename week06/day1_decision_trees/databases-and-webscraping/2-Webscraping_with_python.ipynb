{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping from a Web Page with Python\n",
    "\n",
    "Scraping a web site basically comes down to making a request from Python and parsing through the HTML that is returned from each page. For each of these tasks we have a Python library, `requests` and `bs4`, respectively.\n",
    "\n",
    "### Requests Library\n",
    "\n",
    "The [requests](http://docs.python-requests.org/en/latest/index.html) library is designed to simplify the process of making http requests within Python. The interface is mind-bogglingly simple. Instantiate a requests object to the request, this will mostly be a `get`, with the URL and optional parameters you'd like passed through the request. That instance make the results of the request available via attributes/methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "fun_cheap = 'http://sf.funcheap.com'\n",
    "r = requests.get('http://sf.funcheap.com/2018/03/25/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.text[:1000] # First 1000 characters of the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Info from a Web Page\n",
    "\n",
    "Now that we can gain easy access to the HMTL for a web page, we need some way to pull the desired content from it. Luckily there is already a system in place to do this. With a combination of HMTL and CSS selectors we can identify the information on a HMTL page that we wish to retrieve and grab it with [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element Parent / Child Relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace like so:**  `<p></p>`\n",
    "\n",
    "**Elements can have parents and children:**\n",
    "\n",
    "```html\n",
    "<body>\n",
    "    <div>I am inside the parent element\n",
    "        <div>I am inside a child element</div>\n",
    "        <div>I am inside another child element</div>\n",
    "        <div>I am inside yet another child element</div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "\n",
    "## Element Attributes\n",
    "\n",
    "Elements can also have attributes!  Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- id\n",
    "- href\n",
    "- title\n",
    "- name\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <title>The title of this web page</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <h1>My Photos</h1>\n",
    "  <div class='intro'>\n",
    "    <p>These are some photos of my trips.</p>\n",
    "    <img src=\"me.png\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Italy</h3>\n",
    "  <div class='country' id='venice'>\n",
    "    <img src=\"venice1.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"venice2.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"rome.png\" alt=\"Roma\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Germany</h3>\n",
    "  <div class='country'>\n",
    "    <img src=\"berlin.png\" alt=\"Berlin\">\n",
    "  </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using css selectors with BeautifulSoup\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods find vs findall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"country\" id=\"venice\">\n",
       "<img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       "<img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       "<img alt=\"Roma\" src=\"rome.png\"/>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('div', attrs={'class':'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"country\" id=\"venice\">\n",
       " <img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       " <img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       " <img alt=\"Roma\" src=\"rome.png\"/>\n",
       " </div>, <div class=\"country\">\n",
       " <img alt=\"Berlin\" src=\"berlin.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', attrs={'class':'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"country\" id=\"venice\">\n",
       " <img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       " <img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       " <img alt=\"Roma\" src=\"rome.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', attrs={'class':'country', 'id':'venice'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"intro\">\n",
       " <p>These are some photos of my trips.</p>\n",
       " <img src=\"me.png\"/>\n",
       " </div>, <h3>Italy</h3>, <div class=\"country\" id=\"venice\">\n",
       " <img alt=\"Venice\" src=\"venice1.png\"/> <br/>\n",
       " <img alt=\"Venice\" src=\"venice2.png\"/> <br/>\n",
       " <img alt=\"Roma\" src=\"rome.png\"/>\n",
       " </div>, <h3>Germany</h3>, <div class=\"country\">\n",
       " <img alt=\"Berlin\" src=\"berlin.png\"/>\n",
       " </div>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').find_next_siblings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"intro\">\n",
       " <p>These are some photos of my trips.</p>\n",
       " <img src=\"me.png\"/>\n",
       " </div>, <h1>My Photos</h1>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h3').find_previous_siblings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .elements attributes\n",
    "\n",
    "The `.next_element` attribute of a string or tag points to whatever was parsed immediately afterwards. It might be the same as `.next_sibling`, but itâ€™s usually drastically different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"intro\">\n",
       "<p>These are some photos of my trips.</p>\n",
       "<img src=\"me.png\"/>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').next_element.next_element.next_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting css selector information on a webpage\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAABkAAAAWCAYAAAA1vze2AAAB6UlEQVRIDd1U28s5URRd45ZLyCWEcnkRIUVe/RH+XeUZDyQPHrwIIaHw4BJ+rdM3GtOZvtGv73v4dk1zzpl91tp77T1bOR6PT/ywWX4YX8D/ColNlslms8FwOMR0OsX9fpe5vM4sFgtCoRAqlQrS6fTrXLuQksznc2y3W9TrdTyf35dsuVyKoD4iOZ1OsFqtKBaL2oAM17fbDaPRyPC7YU3MZKBFfTwe2u3b2pDkzeubTTAYRDabNfSS1kTmzczW67WQ0eFwwOVywWazgYVnLYzqQayPSFqtFqh/OBxGMplEJBKB2+2G3W4HiVVSfZCmSXiR4N1uF5PJROA4nU5xFo/HkUqlkMlk4Pf79RzmM1EUBYlEQkR9uVwE0Pl8xmKxEDLudjtB8F8kRKVElERrgUAAtVoN1WpVSKf9pq5NdxczYZR8+A+p5vF4EIvFwDebQGbSUwLy0RtBKBmLzFFSKpWES6fTwWw207u/9ops1I/HY/R6PSENZxfbtdlsikuDwQDtdhvlchmFQgEcQf1+H2yCRqMhGuCF/rV4F/jrkNpTkv1+L2YXW1Q1SpPL5ZDP5xGNRuH1esUnBrZaraQk0kxUQNn7er3icDjA5/MJ2ejDWccfVa2P/t7HJHoAM3tp4c1c/MTn75D8A0Qxlq1KHkx8AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Go on the page you want to scrape  \n",
    "2) Open the inspector tool (right click + inspect or cmd + alt + i)  \n",
    "3) Click on the icon with the mouse: ![image.png](attachment:image.png)\n",
    "4) Select the element in the page you want to scrape. The HTML element will be shown on the right\n",
    "\n",
    "**Note:** You need to repeat that for all the elements you want to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xpath'></a>\n",
    "\n",
    "## Enter XPath and scrapy \n",
    "\n",
    "XPath uses path expressions to select nodes or node-sets in an HTML/XML document. These path expressions look very much like the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xpath'></a>\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Understanding how to identify elements and attributes within HTML documents gives us the capability to write simple expressions that create structured data.  We can think os XPath like a query language for querying HTML.\n",
    "\n",
    "To make this process easier to deal with, we will be using ChroPath XPath helper, which is a Chrome addon.  It's not necessary, but highly recommended to help build XPath expressions.\n",
    "\n",
    "[chroPath](https://chrome.google.com/webstore/detail/chropath/ljngjbnaijcbncmcnjfhigebomdlkcjo?hl=en)\n",
    "=> to get the Xpath\n",
    "\n",
    "[XPath Helper](https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en)\n",
    "=> to verify them\n",
    "\n",
    "XPath expressions can select elements, element attributes, and element text.  These selections can be either to a single item, or multiple items.  Generally, if you're not specific enough, you will end up selecting multiple elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting elements matching an _attribute_\n",
    "\n",
    "This will be one of the most common ways you will select items.  HTML DOM elements will be more differentiated based on their \"class\" and \"id\" variables.  Mainly, these types of attributes are used by web developers to refer to specfic elements or a broad set of elements to apply visual characteristics using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "after that each `/` added will move to the next child element.\n",
    "\n",
    "**Generally**\n",
    "\n",
    "- \"class\" attributes within elements usually refer to multiple items\n",
    "- \"id\" attributes are supposed to be unique, but not always\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go back the above example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<head>\n",
    "  <title>The title of this web page</title>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "  <h1>My Photos</h1>\n",
    "  <div class='intro'>\n",
    "    <p>These are some photos of my trips.</p>\n",
    "    <img src=\"me.png\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Italy</h3>\n",
    "  <div class='country' id='venice'>\n",
    "    <img src=\"venice1.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"venice2.png\" alt=\"Venice\"> <br />\n",
    "    <img src=\"rome.png\" alt=\"Roma\">\n",
    "  </div>\n",
    "\n",
    "  <h3>Germany</h3>\n",
    "  <div class='country'>\n",
    "    <img src=\"berlin.png\" alt=\"Berlin\">\n",
    "  </div>\n",
    "</body>\n",
    "\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<div class=\"country\" id=\"venice\">\\n'\n",
      " '    <img src=\"venice1.png\" alt=\"Venice\"> <br>\\n'\n",
      " '    <img src=\"venice2.png\" alt=\"Venice\"> <br>\\n'\n",
      " '    <img src=\"rome.png\" alt=\"Roma\">\\n'\n",
      " '  </div>',\n",
      " '<div class=\"country\">\\n    <img src=\"berlin.png\" alt=\"Berlin\">\\n  </div>']\n"
     ]
    }
   ],
   "source": [
    "# soup.find_all('div', attrs={'class':'country'})\n",
    "# becomes with Xpath\n",
    "from pprint import pprint\n",
    "pprint(Selector(text=html).xpath('//div[@class=\"country\"]').extract())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<div class=\"country\" id=\"venice\">\\n'\n",
      " '    <img src=\"venice1.png\" alt=\"Venice\"> <br>\\n'\n",
      " '    <img src=\"venice2.png\" alt=\"Venice\"> <br>\\n'\n",
      " '    <img src=\"rome.png\" alt=\"Roma\">\\n'\n",
      " '  </div>']\n"
     ]
    }
   ],
   "source": [
    "# soup.find_all('div', attrs={'class':'country', 'id':'venice'})\n",
    "# becomes:\n",
    "pprint(Selector(text=html).xpath('//div[@class=\"country\"][@id=\"venice\"]').extract())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<p>These are some photos of my trips.</p>']\n"
     ]
    }
   ],
   "source": [
    "# [e for e in soup.find('div', attrs={'class':'intro'}).children][:2]\n",
    "# becomes:\n",
    "pprint(Selector(text=html).xpath('//div[@class=\"intro\"]/p').extract())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either Beautifulsoup (css) or scrapy Selector (Xpath), Create a function that scrape all the articles on techcrunch homepage.\n",
    "https://techcrunch.com/\n",
    "\n",
    "**Bonus:** Implement a recursive loop to load more articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
