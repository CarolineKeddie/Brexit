{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Extracting Base Estimators from Bagged Models \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will have to make use of the attributes available with sklearn's [BaggingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). In particular\n",
    "you will need to investigate what you can do with \n",
    "- `.base_estimator_`\n",
    "- `.estimators_`\n",
    "- `.estimators_samples_`\n",
    "- `.estimators_features_`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Load-the-breast-cancer-data.\" data-toc-modified-id=\"1.-Load-the-breast-cancer-data.-1\">1. Load the breast cancer data.</a></span></li><li><span><a href=\"#2.-Load-required-sklearn-packages.\" data-toc-modified-id=\"2.-Load-required-sklearn-packages.-2\">2. Load required sklearn packages.</a></span></li><li><span><a href=\"#3.-Make-a-train-test-split.\" data-toc-modified-id=\"3.-Make-a-train-test-split.-3\">3. Make a train-test split.</a></span></li><li><span><a href=\"#4.-Create-and-fit-a-BaggingClassifier-with-a-DecisionTreeClassifier-base-estimator.\" data-toc-modified-id=\"4.-Create-and-fit-a-BaggingClassifier-with-a-DecisionTreeClassifier-base-estimator.-4\">4. Create and fit a <code>BaggingClassifier</code> with a <code>DecisionTreeClassifier</code> base estimator.</a></span></li><li><span><a href=\"#5.-Pull-out-the-base-estimator-from-the-ensemble-model.\" data-toc-modified-id=\"5.-Pull-out-the-base-estimator-from-the-ensemble-model.-5\">5. Pull out the base estimator from the ensemble model.</a></span></li><li><span><a href=\"#6.-Pull-out-all-the-base-estimators.\" data-toc-modified-id=\"6.-Pull-out-all-the-base-estimators.-6\">6. Pull out <em>all</em> the base estimators.</a></span></li><li><span><a href=\"#7.-Get-the-features-used-in-each-of-the-bagged-base-estimators.\" data-toc-modified-id=\"7.-Get-the-features-used-in-each-of-the-bagged-base-estimators.-7\">7. Get the features used in each of the bagged base estimators.</a></span></li><li><span><a href=\"#8.-Create-a-list-of-the-features-used-in-the-first-base-estimator.\" data-toc-modified-id=\"8.-Create-a-list-of-the-features-used-in-the-first-base-estimator.-8\">8. Create a list of the features used in the first base estimator.</a></span></li><li><span><a href=\"#9.-Get-out-the-samples-used-in-our-first-base-estimator.\" data-toc-modified-id=\"9.-Get-out-the-samples-used-in-our-first-base-estimator.-9\">9. Get out the samples used in our first base estimator.</a></span></li><li><span><a href=\"#10.-Get-out-the-target-subsample-for-the-estimator.\" data-toc-modified-id=\"10.-Get-out-the-target-subsample-for-the-estimator.-10\">10. Get out the target subsample for the estimator.</a></span></li><li><span><a href=\"#11.-Fit-a-decision-tree-equivalent-to-our-first-base-estimator.\" data-toc-modified-id=\"11.-Fit-a-decision-tree-equivalent-to-our-first-base-estimator.-11\">11. Fit a decision tree equivalent to our first base estimator.</a></span></li><li><span><a href=\"#12.-Bonus:-Take-each-of-the-decision-trees-from-the-ensemble-above-and-obtain-its-predictions-for-the-target-variable-in-the-test-set.-Use-majority-voting-to-obtain-the-ensemble-prediction-for-the-target-label.-Compare-with-the-bagging-classifier-score.\" data-toc-modified-id=\"12.-Bonus:-Take-each-of-the-decision-trees-from-the-ensemble-above-and-obtain-its-predictions-for-the-target-variable-in-the-test-set.-Use-majority-voting-to-obtain-the-ensemble-prediction-for-the-target-label.-Compare-with-the-bagging-classifier-score.-12\">12. Bonus: Take each of the decision trees from the ensemble above and obtain its predictions for the target variable in the test set. Use majority voting to obtain the ensemble prediction for the target label. Compare with the bagging classifier score.</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the breast cancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Converting data into a dataframe structure\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "# Setting up our Y value as well\n",
    "y = pd.Series(data['target'])\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load required sklearn packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create and fit a `BaggingClassifier` with a `DecisionTreeClassifier` base estimator.\n",
    "\n",
    "- Fit on the training data.\n",
    "- Report the score on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.5, n_estimators=50, n_jobs=1, oob_score=True,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our classifier and our bag\n",
    "DT = DecisionTreeClassifier()\n",
    "BC = BaggingClassifier(base_estimator=DT, n_estimators=50, max_features=0.5,\n",
    "                       max_samples=0.5, oob_score=True)\n",
    "\n",
    "# Fitting the Bag\n",
    "BC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = BC.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9507042253521126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BC.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pull out the base estimator from the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting our bag's base model\n",
    "# We can only have one base model so our estimator models cannot have varying parameters\n",
    "# The Random_state is a reference seed.\n",
    "BC.base_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pull out *all* the base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1028862084, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=870353631, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=788373214, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=1419052930, splitter='best'),\n",
       " DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False,\n",
       "             random_state=873768326, splitter='best')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the rest of our bag models.\n",
    "BC.estimators_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get the features used in each of the bagged base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([19,  0, 14,  6, 26, 16,  9, 15, 25, 20, 21,  5,  3, 24,  1]),\n",
       " array([ 7, 26, 21, 17, 18, 23,  6,  8, 22, 12, 28,  0, 13, 27, 15]),\n",
       " array([18, 16, 26, 10,  6, 14,  0, 23, 29,  4,  7, 12, 24, 28, 19]),\n",
       " array([15, 22, 12, 26,  2, 19, 28, 25,  0,  8, 21, 23, 27, 11,  3]),\n",
       " array([15, 24, 10,  7,  1, 28, 12, 16, 18,  5, 17, 19, 13,  9, 23])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the features in each of our bagged models,\n",
    "# that is their index values of the list of feature names\n",
    "BC.estimators_features_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a list of the features used in the first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False,\n",
       "            random_state=1028862084, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the parameters for the first decision tree in our bag?\n",
    "BC.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  0, 14,  6, 26, 16,  9, 15, 25, 20, 21,  5,  3, 24,  1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the features used in the first model\n",
    "BC.estimators_features_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fractal dimension error',\n",
       " 'mean radius',\n",
       " 'smoothness error',\n",
       " 'mean concavity',\n",
       " 'worst concavity',\n",
       " 'concavity error',\n",
       " 'mean fractal dimension',\n",
       " 'compactness error',\n",
       " 'worst compactness',\n",
       " 'worst radius',\n",
       " 'worst texture',\n",
       " 'mean compactness',\n",
       " 'mean area',\n",
       " 'worst smoothness',\n",
       " 'mean texture']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of the selected features.\n",
    "sub_features = []\n",
    "for feature in BC.estimators_features_[0]:\n",
    "    sub_features.append(data['feature_names'][feature])\n",
    "sub_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Get out the samples used in our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the samples used in the first model?\n",
    "samples = BC.estimators_samples_[0]\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[178, 153, 167, 170, 176, 164, 174, 171, 173, 166]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of samples included in each ensemble member (remember max_samples)\n",
    "[BC.estimators_samples_[i].sum() for i in range(len(BC.estimators_))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the True Samples from our DT to sub down to X_train\n",
    "X_train_0 = X_train.loc[samples,sub_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>mean texture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.001711</td>\n",
       "      <td>20.64</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.41590</td>\n",
       "      <td>0.02681</td>\n",
       "      <td>0.05478</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.30550</td>\n",
       "      <td>25.37</td>\n",
       "      <td>23.17</td>\n",
       "      <td>0.10760</td>\n",
       "      <td>1335.0</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>17.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.003351</td>\n",
       "      <td>12.81</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.02758</td>\n",
       "      <td>0.00618</td>\n",
       "      <td>0.06133</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.05445</td>\n",
       "      <td>13.63</td>\n",
       "      <td>16.15</td>\n",
       "      <td>0.03774</td>\n",
       "      <td>508.8</td>\n",
       "      <td>0.1162</td>\n",
       "      <td>13.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.006517</td>\n",
       "      <td>11.26</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.092740</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.08099</td>\n",
       "      <td>0.06233</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.18430</td>\n",
       "      <td>11.86</td>\n",
       "      <td>22.33</td>\n",
       "      <td>0.11810</td>\n",
       "      <td>394.1</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>19.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.002256</td>\n",
       "      <td>19.53</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.39950</td>\n",
       "      <td>0.02664</td>\n",
       "      <td>0.05313</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>0.40970</td>\n",
       "      <td>27.90</td>\n",
       "      <td>45.41</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>32.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.002606</td>\n",
       "      <td>10.32</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.04384</td>\n",
       "      <td>0.01012</td>\n",
       "      <td>0.06201</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.08842</td>\n",
       "      <td>11.25</td>\n",
       "      <td>21.77</td>\n",
       "      <td>0.04994</td>\n",
       "      <td>324.9</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>16.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fractal dimension error  mean radius  smoothness error  mean concavity  \\\n",
       "373                 0.001711        20.64          0.006211        0.152700   \n",
       "179                 0.003351        12.81          0.008534        0.009193   \n",
       "288                 0.006517        11.26          0.015740        0.092740   \n",
       "219                 0.002256        19.53          0.005539        0.114500   \n",
       "546                 0.002606        10.32          0.007086        0.010120   \n",
       "\n",
       "     worst concavity  concavity error  mean fractal dimension  \\\n",
       "373          0.41590          0.02681                 0.05478   \n",
       "179          0.02758          0.00618                 0.06133   \n",
       "288          0.15460          0.08099                 0.06233   \n",
       "219          0.39950          0.02664                 0.05313   \n",
       "546          0.04384          0.01012                 0.06201   \n",
       "\n",
       "     compactness error  worst compactness  worst radius  worst texture  \\\n",
       "373           0.018950            0.30550         25.37          23.17   \n",
       "179           0.006364            0.05445         13.63          16.15   \n",
       "288           0.082620            0.18430         11.86          22.33   \n",
       "219           0.026440            0.40970         27.90          45.41   \n",
       "546           0.007247            0.08842         11.25          21.77   \n",
       "\n",
       "     mean compactness  mean area  worst smoothness  mean texture  \n",
       "373           0.10760     1335.0            0.1562         17.35  \n",
       "179           0.03774      508.8            0.1162         13.06  \n",
       "288           0.11810      394.1            0.1028         19.96  \n",
       "219           0.11300     1223.0            0.1408         32.47  \n",
       "546           0.04994      324.9            0.1285         16.35  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Get out the target subsample for the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the y_train sub sample used.\n",
    "#target = pd.DataFrame(y_train)\n",
    "y_train_0 = y_train[samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Fit a decision tree equivalent to our first base estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the Decision Tree in our First base model of our bagged classifier.\n",
    "DTC_0 = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                              max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
    "                              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                              presort=False, random_state=BC.estimators_[0].random_state, splitter='best')\n",
    "\n",
    "# Setting the model's X and Y values\n",
    "#X0 = data2[sub_features]\n",
    "#Y0 = target2#[0]\n",
    "\n",
    "# Fitting the model\n",
    "DTC_0.fit(X_train_0, y_train_0)\n",
    "\n",
    "# accuracy on the test set\n",
    "predictions_DTC_0 = DTC_0.predict(X_test[sub_features])\n",
    "accuracy_score(y_test, predictions_DTC_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Bonus: Take each of the decision trees from the ensemble above and obtain its predictions for the target variable in the test set. Use majority voting to obtain the ensemble prediction for the target label. Compare with the bagging classifier score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951048951048951\n",
      "0.8811188811188811\n",
      "0.9230769230769231\n",
      "0.9230769230769231\n",
      "0.8881118881118881\n",
      "0.9020979020979021\n",
      "0.9230769230769231\n",
      "0.9440559440559441\n",
      "0.9370629370629371\n",
      "0.8811188811188811\n",
      "0.9370629370629371\n",
      "0.972027972027972\n",
      "0.8951048951048951\n",
      "0.951048951048951\n",
      "0.958041958041958\n",
      "0.9230769230769231\n",
      "0.8811188811188811\n",
      "0.9020979020979021\n",
      "0.951048951048951\n",
      "0.916083916083916\n",
      "0.9090909090909091\n",
      "0.9370629370629371\n",
      "0.972027972027972\n",
      "0.9300699300699301\n",
      "0.9440559440559441\n",
      "0.9370629370629371\n",
      "0.965034965034965\n",
      "0.951048951048951\n",
      "0.8881118881118881\n",
      "0.9370629370629371\n",
      "0.9440559440559441\n",
      "0.951048951048951\n",
      "0.916083916083916\n",
      "0.951048951048951\n",
      "0.916083916083916\n",
      "0.9440559440559441\n",
      "0.9300699300699301\n",
      "0.9020979020979021\n",
      "0.916083916083916\n",
      "0.9440559440559441\n",
      "0.9440559440559441\n",
      "0.8951048951048951\n",
      "0.9370629370629371\n",
      "0.9300699300699301\n",
      "0.9020979020979021\n",
      "0.9370629370629371\n",
      "0.9440559440559441\n",
      "0.916083916083916\n",
      "0.8461538461538461\n",
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "df_predictions = pd.DataFrame()\n",
    "df_probabilities = pd.DataFrame()\n",
    "for i, estimator in enumerate(BC.estimators_):\n",
    "    # Creating a list of the selected features.\n",
    "    sub_features = []\n",
    "    for feature in BC.estimators_features_[i]:\n",
    "        sub_features.append(data['feature_names'][feature])\n",
    "    # sub_features\n",
    "\n",
    "    # What are the samples used in the i-th model?\n",
    "    samples = BC.estimators_samples_[i]\n",
    "    data_current = X_train.loc[samples,sub_features]\n",
    "    target_current = y_train[samples]\n",
    "\n",
    "    # Setting the Decision Tree in our i-th base model of our bagged classifier.\n",
    "    DTC0 = estimator\n",
    "    \n",
    "    # Setting the model's X and Y values\n",
    "    #X0 = data_current[sub_features]\n",
    "    #Y0 = target_current[0]\n",
    "\n",
    "    # Fitting the model\n",
    "    DTC0.fit(data_current,target_current)\n",
    "\n",
    "    # accuracy on the test set\n",
    "    predictions_DTC0 = DTC0.predict(X_test[sub_features])\n",
    "    probabilities_DTC0 = DTC0.predict_proba(X_test[sub_features])\n",
    "    df_predictions['predictions_'+str(i)] = predictions_DTC0\n",
    "    df_probabilities['probabilities_0_'+str(i)] = probabilities_DTC0[:, 0]\n",
    "    df_probabilities['probabilities_1_'+str(i)] = probabilities_DTC0[:, 1]\n",
    "    accuracy = accuracy_score(y_test, predictions_DTC0)\n",
    "    accuracies.append(accuracy)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265734265734267"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = []\n",
    "ones = []\n",
    "for i in range(len(df_predictions)):\n",
    "    counts = df_predictions.iloc[i].value_counts()\n",
    "    try:\n",
    "        zeros.append(counts[0])\n",
    "    except:\n",
    "        zeros.append(0)\n",
    "    try:\n",
    "        ones.append(counts[1])\n",
    "    except:\n",
    "        ones.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_0</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>predictions_2</th>\n",
       "      <th>predictions_3</th>\n",
       "      <th>predictions_4</th>\n",
       "      <th>predictions_5</th>\n",
       "      <th>predictions_6</th>\n",
       "      <th>predictions_7</th>\n",
       "      <th>predictions_8</th>\n",
       "      <th>predictions_9</th>\n",
       "      <th>...</th>\n",
       "      <th>predictions_43</th>\n",
       "      <th>predictions_44</th>\n",
       "      <th>predictions_45</th>\n",
       "      <th>predictions_46</th>\n",
       "      <th>predictions_47</th>\n",
       "      <th>predictions_48</th>\n",
       "      <th>predictions_49</th>\n",
       "      <th>zeros</th>\n",
       "      <th>ones</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions_0  predictions_1  predictions_2  predictions_3  predictions_4  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              1              1              1              1   \n",
       "2              1              1              0              1              0   \n",
       "3              1              1              1              1              1   \n",
       "4              1              1              1              1              1   \n",
       "\n",
       "   predictions_5  predictions_6  predictions_7  predictions_8  predictions_9  \\\n",
       "0              0              0              0              0              0   \n",
       "1              1              1              1              1              1   \n",
       "2              1              1              1              1              1   \n",
       "3              1              1              1              1              1   \n",
       "4              1              1              1              1              1   \n",
       "\n",
       "      ...      predictions_43  predictions_44  predictions_45  predictions_46  \\\n",
       "0     ...                   0               0               0               0   \n",
       "1     ...                   1               1               1               1   \n",
       "2     ...                   1               1               1               0   \n",
       "3     ...                   1               1               1               1   \n",
       "4     ...                   1               1               1               1   \n",
       "\n",
       "   predictions_47  predictions_48  predictions_49  zeros  ones  prediction  \n",
       "0               0               0               0     50     0           0  \n",
       "1               1               1               1      0    50           1  \n",
       "2               1               1               1     11    39           1  \n",
       "3               1               1               1      0    50           1  \n",
       "4               1               1               1      1    49           1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions['zeros'] = zeros\n",
    "df_predictions['ones'] = ones\n",
    "df_predictions['prediction'] = df_predictions[['zeros', 'ones']].apply(\n",
    "    lambda x: 1 if x[1] > x[0] else 0, axis=1)\n",
    "\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, df_predictions.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790209790209791"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check agreement with bagging score\n",
    "accuracy_score(y_test, df_predictions.prediction) - \\\n",
    "    accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
