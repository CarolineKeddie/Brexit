{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Bias-variance lab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will explore how bias and variance change using a dataset on college statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict,train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        College Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "0  Abilene Christian University     Yes  1660    1232     721         23   \n",
       "1            Adelphi University     Yes  2186    1924     512         16   \n",
       "2                Adrian College     Yes  1428    1097     336         22   \n",
       "\n",
       "   Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  Personal  \\\n",
       "0         52         2885          537      7440        3300    450      2200   \n",
       "1         29         2683         1227     12280        6450    750      1500   \n",
       "2         50         1036           99     11250        3750    400      1165   \n",
       "\n",
       "   PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0   70        78       18.1           12    7041         60  \n",
       "1   29        30       12.2           16   10527         56  \n",
       "2   53        66       12.9           30    8735         54  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('../../../../../resource-datasets/college_stats/College.csv')\n",
    "college.rename(columns={'Unnamed: 0':'College'}, inplace=True)\n",
    "college.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the names of the variables and the data types contained in the college data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "College         object\n",
       "Private         object\n",
       "Apps             int64\n",
       "Accept           int64\n",
       "Enroll           int64\n",
       "Top10perc        int64\n",
       "Top25perc        int64\n",
       "F.Undergrad      int64\n",
       "P.Undergrad      int64\n",
       "Outstate         int64\n",
       "Room.Board       int64\n",
       "Books            int64\n",
       "Personal         int64\n",
       "PhD              int64\n",
       "Terminal         int64\n",
       "S.F.Ratio      float64\n",
       "perc.alumni      int64\n",
       "Expend           int64\n",
       "Grad.Rate        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the column names (replace \".\" by \"_\" and transform to lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.columns = [col.lower().replace('.','_') for col in college.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the variable \"Private\" into 1s and 0s rather than yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "college.private = college.private.map(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose \"grad_rate\" as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = college['grad_rate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature matrix containing all variables except \"grad_rate\" and the college names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>apps</th>\n",
       "      <th>accept</th>\n",
       "      <th>enroll</th>\n",
       "      <th>top10perc</th>\n",
       "      <th>top25perc</th>\n",
       "      <th>f_undergrad</th>\n",
       "      <th>p_undergrad</th>\n",
       "      <th>outstate</th>\n",
       "      <th>room_board</th>\n",
       "      <th>books</th>\n",
       "      <th>personal</th>\n",
       "      <th>phd</th>\n",
       "      <th>terminal</th>\n",
       "      <th>s_f_ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>expend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   private  apps  accept  enroll  top10perc  top25perc  f_undergrad  \\\n",
       "0        1  1660    1232     721         23         52         2885   \n",
       "1        1  2186    1924     512         16         29         2683   \n",
       "\n",
       "   p_undergrad  outstate  room_board  books  personal  phd  terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "\n",
       "   s_f_ratio  perc_alumni  expend  \n",
       "0       18.1           12    7041  \n",
       "1       12.2           16   10527  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = college.iloc[:,1:-1]\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the standard scaler to rescale your features and response\n",
    "\n",
    "Hint: to rescale the response variable, you will first have to bring it intro 2D-array form and later to retransform it into 1D-array form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>private</th>\n",
       "      <th>apps</th>\n",
       "      <th>accept</th>\n",
       "      <th>enroll</th>\n",
       "      <th>top10perc</th>\n",
       "      <th>top25perc</th>\n",
       "      <th>f_undergrad</th>\n",
       "      <th>p_undergrad</th>\n",
       "      <th>outstate</th>\n",
       "      <th>room_board</th>\n",
       "      <th>books</th>\n",
       "      <th>personal</th>\n",
       "      <th>phd</th>\n",
       "      <th>terminal</th>\n",
       "      <th>s_f_ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>expend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.612553</td>\n",
       "      <td>-0.346882</td>\n",
       "      <td>-0.321205</td>\n",
       "      <td>-0.063509</td>\n",
       "      <td>-0.258583</td>\n",
       "      <td>-0.191827</td>\n",
       "      <td>-0.168116</td>\n",
       "      <td>-0.209207</td>\n",
       "      <td>-0.746356</td>\n",
       "      <td>-0.964905</td>\n",
       "      <td>-0.602312</td>\n",
       "      <td>1.270045</td>\n",
       "      <td>-0.163028</td>\n",
       "      <td>-0.115729</td>\n",
       "      <td>1.013776</td>\n",
       "      <td>-0.867574</td>\n",
       "      <td>-0.501910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612553</td>\n",
       "      <td>-0.210884</td>\n",
       "      <td>-0.038703</td>\n",
       "      <td>-0.288584</td>\n",
       "      <td>-0.655656</td>\n",
       "      <td>-1.353911</td>\n",
       "      <td>-0.209788</td>\n",
       "      <td>0.244307</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>1.909208</td>\n",
       "      <td>1.215880</td>\n",
       "      <td>0.235515</td>\n",
       "      <td>-2.675646</td>\n",
       "      <td>-3.378176</td>\n",
       "      <td>-0.477704</td>\n",
       "      <td>-0.544572</td>\n",
       "      <td>0.166110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.612553</td>\n",
       "      <td>-0.406866</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.478121</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>-0.292878</td>\n",
       "      <td>-0.549565</td>\n",
       "      <td>-0.497090</td>\n",
       "      <td>0.201305</td>\n",
       "      <td>-0.554317</td>\n",
       "      <td>-0.905344</td>\n",
       "      <td>-0.259582</td>\n",
       "      <td>-1.204845</td>\n",
       "      <td>-0.931341</td>\n",
       "      <td>-0.300749</td>\n",
       "      <td>0.585935</td>\n",
       "      <td>-0.177290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.612553</td>\n",
       "      <td>-0.668261</td>\n",
       "      <td>-0.681682</td>\n",
       "      <td>-0.692427</td>\n",
       "      <td>1.840231</td>\n",
       "      <td>1.677612</td>\n",
       "      <td>-0.658079</td>\n",
       "      <td>-0.520752</td>\n",
       "      <td>0.626633</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>-0.602312</td>\n",
       "      <td>-0.688173</td>\n",
       "      <td>1.185206</td>\n",
       "      <td>1.175657</td>\n",
       "      <td>-1.615274</td>\n",
       "      <td>1.151188</td>\n",
       "      <td>1.792851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.612553</td>\n",
       "      <td>-0.726176</td>\n",
       "      <td>-0.764555</td>\n",
       "      <td>-0.780735</td>\n",
       "      <td>-0.655656</td>\n",
       "      <td>-0.596031</td>\n",
       "      <td>-0.711924</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>-0.716508</td>\n",
       "      <td>-0.216723</td>\n",
       "      <td>1.518912</td>\n",
       "      <td>0.235515</td>\n",
       "      <td>0.204672</td>\n",
       "      <td>-0.523535</td>\n",
       "      <td>-0.553542</td>\n",
       "      <td>-1.675079</td>\n",
       "      <td>0.241803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    private      apps    accept    enroll  top10perc  top25perc  f_undergrad  \\\n",
       "0  0.612553 -0.346882 -0.321205 -0.063509  -0.258583  -0.191827    -0.168116   \n",
       "1  0.612553 -0.210884 -0.038703 -0.288584  -0.655656  -1.353911    -0.209788   \n",
       "2  0.612553 -0.406866 -0.376318 -0.478121  -0.315307  -0.292878    -0.549565   \n",
       "3  0.612553 -0.668261 -0.681682 -0.692427   1.840231   1.677612    -0.658079   \n",
       "4  0.612553 -0.726176 -0.764555 -0.780735  -0.655656  -0.596031    -0.711924   \n",
       "\n",
       "   p_undergrad  outstate  room_board     books  personal       phd  terminal  \\\n",
       "0    -0.209207 -0.746356   -0.964905 -0.602312  1.270045 -0.163028 -0.115729   \n",
       "1     0.244307  0.457496    1.909208  1.215880  0.235515 -2.675646 -3.378176   \n",
       "2    -0.497090  0.201305   -0.554317 -0.905344 -0.259582 -1.204845 -0.931341   \n",
       "3    -0.520752  0.626633    0.996791 -0.602312 -0.688173  1.185206  1.175657   \n",
       "4     0.009005 -0.716508   -0.216723  1.518912  0.235515  0.204672 -0.523535   \n",
       "\n",
       "   s_f_ratio  perc_alumni    expend  \n",
       "0   1.013776    -0.867574 -0.501910  \n",
       "1  -0.477704    -0.544572  0.166110  \n",
       "2  -0.300749     0.585935 -0.177290  \n",
       "3  -1.615274     1.151188  1.792851  \n",
       "4  -0.553542    -1.675079  0.241803  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled,columns=X.columns)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.31825194, -0.55126184, -0.66776679, -0.37650442])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape = (-1,1)\n",
    "y = scaler.fit_transform(y)\n",
    "y.shape = (len(y),)\n",
    "y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a 10-fold cross-validated linear regression model for grad_rate using all other features. Evaluate the model performance using cross_val_score, obtain the r2_score and mean_squared_error for each fold and averaged over all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44921644 0.35875931 0.53650887 0.48549145 0.17445097 0.38775448\n",
      " 0.17393223 0.43964213 0.61095627 0.3575135 ]\n",
      "0.3974225630451289\n",
      "[0.53143428 0.67709959 0.47839047 0.58839311 0.75469774 0.58657544\n",
      " 0.64064922 0.55468051 0.36236785 0.6052721 ]\n",
      "0.5779560308061675\n"
     ]
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "\n",
    "lr_scores_r2 = cross_val_score(linreg, X, y, cv=10,scoring='r2')\n",
    "\n",
    "print(lr_scores_r2)\n",
    "print(np.mean(lr_scores_r2))\n",
    "\n",
    "lr_scores_mse = - cross_val_score(linreg, X, y, cv=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "print(lr_scores_mse)\n",
    "print(np.mean(lr_scores_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function with the name `predict_from_samples` that will iteratively predict your target from different train-test splits\n",
    "\n",
    "This will be used to calculate the bias and the variance afterwards.\n",
    "We want to produce a range of different models fitted on a random choice of data points and making predictions for the remaining data points.\n",
    "\n",
    "\n",
    "Your function should:\n",
    "\n",
    "1. take the following arguments:\n",
    "    * `model`: a regression model \n",
    "    * `X`: predictor matrix/dataframe \n",
    "    * `y`: target variable \n",
    "    * `number_of_splits`: a number indicating how many times the dataset should be split randomly into training and test sets\n",
    "\n",
    "2. return a dataframe `yhat_tracker` containing columns for \n",
    "    * the true values of `y` (obtained from the `y` passed as an argument)\n",
    "    * the predictions made for y in each of the `number_of_splits` into training/test sets\n",
    "\n",
    "3. in the function body\n",
    "    - initialize the dataframe `yhat_tracker` with a single column `y` for the true values\n",
    "    - initialize a list `rowinds` containing the indices of yhat_tracker\n",
    "    - create a loop over `number_of_splits`\n",
    "        - within the loop, create a train/test split of rowinds\n",
    "        - create training and test sets from y and X by subsetting on the indices obtained from the train/test split\n",
    "        - fit the model on the training data\n",
    "        - obtain predictions for those y which are currently in the test set\n",
    "        - set the predicted values for those `y` which are currently in the training set to `np.nan` \n",
    "        - insert the predictions from the current loop as a new column into `yhat_tracker`\n",
    "    - return yhat_tracker \n",
    "    \n",
    "In the end, the returned data frame should contain one column with the true y-values and `number_of_splits` columns with predicted y-values for the different test sets. Each of the prediction columns contains only as many values as there have been in the test set each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_samples(model, X, y, number_of_splits=100):\n",
    "    \n",
    "    yhat_tracker = pd.DataFrame({'ytrue':y})\n",
    "    \n",
    "    rowinds = list(range(X.shape[0]))\n",
    "    \n",
    "    for i in range(number_of_splits):\n",
    "        \n",
    "        train_inds, test_inds = train_test_split(rowinds, test_size=0.33)\n",
    "                \n",
    "        X_train, Y_train = X.iloc[train_inds, :], y[train_inds]\n",
    "        X_test, Y_test = X.iloc[test_inds, :], y[test_inds]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        yhats = model.predict(X_test)\n",
    "        \n",
    "        yhat_tracker['sample'+str(i+1)] = np.nan\n",
    "        yhat_tracker.iloc[test_inds, -1] = yhats\n",
    "        \n",
    "    return yhat_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different predictor datasets\n",
    "\n",
    "To see what happens to bias and variance as the predictors change, create a few versions of X that have different numbers of predictors in them:\n",
    "\n",
    "* model $X$ from above including all features\n",
    "* a model $X_{small}$ including only one feature (e.g. personal)\n",
    "* a model $X_{overfit}$ created with the patsy formula below \n",
    "    - taking the cube takes into account \n",
    "        - all original features\n",
    "        - all features that could be created by squaring or cubing a single column\n",
    "        - all products of two or three different columns\n",
    "        - all products of the square of one column with a different column\n",
    "        - -1 excludes the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_formula = '~ ('+' + '.join(X.columns)+')**3 -1'\n",
    "X_overfit = patsy.dmatrix(overfit_formula, data=X, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~ (private + apps + accept + enroll + top10perc + top25perc + f_undergrad + p_undergrad + outstate + room_board + books + personal + phd + terminal + s_f_ratio + perc_alumni + expend)**3 -1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overfit_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X[['personal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `predict_from_samples` function you wrote above to get the predicted values for $X$, $X_{small}$, $X_{overfit}$ \n",
    "\n",
    "- Run each of your X through the function with the y target vector. \n",
    "- Recall that the output of your function has the true values of y in one column and then predicted values of y for the different train-test splits in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 17) (777, 1) (777, 833)\n",
      "(777, 101) (777, 101) (777, 101)\n"
     ]
    }
   ],
   "source": [
    "yhats_full = predict_from_samples(linreg, X, y)\n",
    "yhats_small = predict_from_samples(linreg, X_small, y)\n",
    "yhats_over = predict_from_samples(linreg, X_overfit, y)\n",
    "\n",
    "print(X.shape, X_small.shape, X_overfit.shape)\n",
    "print(yhats_full.shape, yhats_small.shape, yhats_over.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ytrue</th>\n",
       "      <th>sample1</th>\n",
       "      <th>sample2</th>\n",
       "      <th>sample3</th>\n",
       "      <th>sample4</th>\n",
       "      <th>sample5</th>\n",
       "      <th>sample6</th>\n",
       "      <th>sample7</th>\n",
       "      <th>sample8</th>\n",
       "      <th>sample9</th>\n",
       "      <th>...</th>\n",
       "      <th>sample91</th>\n",
       "      <th>sample92</th>\n",
       "      <th>sample93</th>\n",
       "      <th>sample94</th>\n",
       "      <th>sample95</th>\n",
       "      <th>sample96</th>\n",
       "      <th>sample97</th>\n",
       "      <th>sample98</th>\n",
       "      <th>sample99</th>\n",
       "      <th>sample100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.318252</td>\n",
       "      <td>-0.512825</td>\n",
       "      <td>-0.529464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.530716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.450349</td>\n",
       "      <td>-0.490560</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.660476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.383850</td>\n",
       "      <td>-0.51344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.572368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.548193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.551262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.255130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.325543</td>\n",
       "      <td>-0.062165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027846</td>\n",
       "      <td>0.124181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049788</td>\n",
       "      <td>0.108399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.667767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086139</td>\n",
       "      <td>0.227121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.376504</td>\n",
       "      <td>0.672275</td>\n",
       "      <td>0.773802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.608037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.741045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.939613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.734722</td>\n",
       "      <td>-0.700904</td>\n",
       "      <td>-0.692327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.903917</td>\n",
       "      <td>-0.787925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.668942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.825031</td>\n",
       "      <td>-0.761754</td>\n",
       "      <td>-0.860531</td>\n",
       "      <td>-0.70686</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ytrue   sample1   sample2   sample3   sample4  sample5   sample6  \\\n",
       "0 -0.318252 -0.512825 -0.529464       NaN       NaN      NaN -0.530716   \n",
       "1 -0.551262       NaN       NaN       NaN -0.255130      NaN       NaN   \n",
       "2 -0.667767       NaN       NaN       NaN  0.097583      NaN  0.162797   \n",
       "3 -0.376504  0.672275  0.773802       NaN  0.723679      NaN  0.608037   \n",
       "4 -2.939613       NaN -0.734722 -0.700904 -0.692327      NaN -0.903917   \n",
       "\n",
       "    sample7   sample8   sample9    ...      sample91  sample92  sample93  \\\n",
       "0       NaN -0.450349 -0.490560    ...           NaN -0.660476       NaN   \n",
       "1       NaN -0.325543 -0.062165    ...     -0.027846  0.124181       NaN   \n",
       "2       NaN  0.082818       NaN    ...      0.129454       NaN       NaN   \n",
       "3       NaN       NaN       NaN    ...           NaN  0.655351       NaN   \n",
       "4 -0.787925       NaN       NaN    ...           NaN       NaN       NaN   \n",
       "\n",
       "   sample94  sample95  sample96  sample97  sample98  sample99  sample100  \n",
       "0 -0.383850  -0.51344       NaN -0.572368       NaN       NaN  -0.548193  \n",
       "1       NaN       NaN       NaN  0.049788  0.108399       NaN        NaN  \n",
       "2       NaN       NaN       NaN  0.086139  0.227121       NaN        NaN  \n",
       "3  0.704469       NaN       NaN       NaN       NaN       NaN   0.741045  \n",
       "4 -0.668942       NaN -0.825031 -0.761754 -0.860531  -0.70686        NaN  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhats_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate bias and variance \n",
    "\n",
    "Below are two functions to calculate bias and variance from the dataframe returned by your function `predict_from_samples`.\n",
    "You can use them to calculate the bias and variance for the models containing different feature combinations. \n",
    "\n",
    "If you have more predictors, variance of prediction should generally go up and bias go down. Likewise, if you have few predictors variance should go down and bias go up.\n",
    "\n",
    "For a bad model, they both might go up a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bias_sq(yhats_df):\n",
    "    # Take out the true values of y that are in the first column:\n",
    "    ytrue = yhats_df.iloc[:,0]\n",
    "    \n",
    "    # Calculate the mean of the predictions, averaged across the columns.\n",
    "    # So, all of the predictions for the true y at row 0 would be averaged together\n",
    "    # and so on for all the rows.\n",
    "    yhat_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # Subtract the true value of y from the mean of the predicted values, and square it.\n",
    "    elementwise_bias_sq = (yhat_means - ytrue)**2\n",
    "    \n",
    "    # Take the mean of those squared bias values (across all y)\n",
    "    mean_bias_sq = np.mean(elementwise_bias_sq)\n",
    "\n",
    "    return mean_bias_sq\n",
    "\n",
    "def calculate_variance(yhats_df):\n",
    "    \n",
    "    # Calculate the mean of the predicted y's across the columns (mean of yhat for each row)\n",
    "    yhats_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # subtract the mean of the yhats from the original yhat values (for each row)\n",
    "    # and square the result. \n",
    "    yhats_devsq = (yhats_df.iloc[:,1:].subtract(yhats_means, axis=0))**2\n",
    "    \n",
    "    # Take the mean of the squared deviations from the mean, then \n",
    "    # take the mean of those to get the overall variance across the y observations\n",
    "    yhats_devsq_means = yhats_devsq.mean(axis=1)\n",
    "    \n",
    "    return np.mean(yhats_devsq_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance full: 0.009049366891939276\n",
      "bias full: 0.5741137047263181\n",
      "variance small: 0.0016063629884423994\n",
      "bias small: 0.9342491633868237\n",
      "variance over: 175.81956568079184\n",
      "bias over: 107.90633141232202\n"
     ]
    }
   ],
   "source": [
    "print(\"variance full:\", calculate_variance(yhats_full))\n",
    "print(\"bias full:\", calculate_bias_sq(yhats_full))\n",
    "print(\"variance small:\", calculate_variance(yhats_small))\n",
    "print(\"bias small:\", calculate_bias_sq(yhats_small))\n",
    "print(\"variance over:\", calculate_variance(yhats_over))\n",
    "print(\"bias over:\", calculate_bias_sq(yhats_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does regularization affect bias and variance?\n",
    "\n",
    "Use lasso and/or ridge regression on your dataset with all the predictor variables. In your function `predict_from_samples` replace `model` with your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso(alpha=2.0)\n",
    "ridge = Ridge(alpha=2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance full: 0.0005702831702019593\n",
      "bias full: 1.0024269587603027\n",
      "variance small: 0.0006215609193647028\n",
      "bias small: 1.0026274719335944\n",
      "variance over: 0.0005023819421557555\n",
      "bias over: 1.002151963589761\n"
     ]
    }
   ],
   "source": [
    "yhats_full = predict_from_samples(lasso, X, y)\n",
    "yhats_small = predict_from_samples(lasso, X_small, y)\n",
    "yhats_over = predict_from_samples(lasso, X_overfit, y)\n",
    "print(\"variance full:\", calculate_variance(yhats_full))\n",
    "print(\"bias full:\", calculate_bias_sq(yhats_full))\n",
    "print(\"variance small:\", calculate_variance(yhats_small))\n",
    "print(\"bias small:\", calculate_bias_sq(yhats_small))\n",
    "print(\"variance over:\", calculate_variance(yhats_over))\n",
    "print(\"bias over:\", calculate_bias_sq(yhats_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance full: 0.0077814844952792065\n",
      "bias full: 0.5710156876387991\n",
      "variance small: 0.0014121554619616642\n",
      "bias small: 0.933413524866396\n",
      "variance over: 3.325046305901924\n",
      "bias over: 2.0050184351656157\n"
     ]
    }
   ],
   "source": [
    "yhats_full = predict_from_samples(ridge, X, y)\n",
    "yhats_small = predict_from_samples(ridge, X_small, y)\n",
    "yhats_over = predict_from_samples(ridge, X_overfit, y)\n",
    "\n",
    "print(\"variance full:\", calculate_variance(yhats_full))\n",
    "print(\"bias full:\", calculate_bias_sq(yhats_full))\n",
    "print(\"variance small:\", calculate_variance(yhats_small))\n",
    "print(\"bias small:\", calculate_bias_sq(yhats_small))\n",
    "print(\"variance over:\", calculate_variance(yhats_over))\n",
    "print(\"bias over:\", calculate_bias_sq(yhats_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
