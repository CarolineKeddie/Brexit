{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Bias-variance lab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will explore how bias and variance change using a dataset on college statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict,train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>College</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelphi University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adrian College</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        College Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "0  Abilene Christian University     Yes  1660    1232     721         23   \n",
       "1            Adelphi University     Yes  2186    1924     512         16   \n",
       "2                Adrian College     Yes  1428    1097     336         22   \n",
       "\n",
       "   Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  Personal  \\\n",
       "0         52         2885          537      7440        3300    450      2200   \n",
       "1         29         2683         1227     12280        6450    750      1500   \n",
       "2         50         1036           99     11250        3750    400      1165   \n",
       "\n",
       "   PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0   70        78       18.1           12    7041         60  \n",
       "1   29        30       12.2           16   10527         56  \n",
       "2   53        66       12.9           30    8735         54  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college = pd.read_csv('../../../../resource-datasets/college_stats/College.csv')\n",
    "college.rename(columns={'Unnamed: 0':'College'}, inplace=True)\n",
    "college.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the names of the variables and the data types contained in the college data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the column names (replace \".\" by \"_\" and transform to lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the variable \"Private\" into 1s and 0s rather than yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose \"grad_rate\" as target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature matrix containing all variables except \"grad_rate\" and the college names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the standard scaler to rescale your features and response\n",
    "\n",
    "Hint: to rescale the response variable, you will first have to bring it intro 2D-array form and later to retransform it into 1D-array form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a 10-fold cross-validated linear regression model for grad_rate using all other features. Evaluate the model performance using cross_val_score, obtain the r2_score and mean_squared_error for each fold and averaged over all folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function with the name `predict_from_samples` that will iteratively predict your target from different train-test splits\n",
    "\n",
    "This will be used to calculate the bias and the variance afterwards.\n",
    "We want to produce a range of different models fitted on a random choice of data points and making predictions for the remaining data points.\n",
    "\n",
    "\n",
    "Your function should:\n",
    "\n",
    "1. take the following arguments:\n",
    "    * `model`: a regression model \n",
    "    * `X`: predictor matrix/dataframe \n",
    "    * `y`: target variable \n",
    "    * `number_of_splits`: a number indicating how many times the dataset should be split randomly into training and test sets\n",
    "\n",
    "2. return a dataframe `yhat_tracker` containing columns for \n",
    "    * the true values of `y` (obtained from the `y` passed as an argument)\n",
    "    * the predictions made for y in each of the `number_of_splits` into training/test sets\n",
    "\n",
    "3. in the function body\n",
    "    - initialize the dataframe `yhat_tracker` with a single column `y` for the true values\n",
    "    - initialize a list `rowinds` containing the indices of yhat_tracker\n",
    "    - create a loop over `number_of_splits`\n",
    "        - within the loop, create a train/test split of rowinds\n",
    "        - create training and test sets from y and X by subsetting on the indices obtained from the train/test split\n",
    "        - fit the model on the training data\n",
    "        - obtain predictions for those y which are currently in the test set\n",
    "        - set the predicted values for those `y` which are currently in the training set to `np.nan` \n",
    "        - insert the predictions from the current loop as a new column into `yhat_tracker`\n",
    "    - return yhat_tracker \n",
    "    \n",
    "In the end, the returned data frame should contain one column with the true y-values and `number_of_splits` columns with predicted y-values for the different test sets. Each of the prediction columns contains only as many values as there have been in the test set each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_samples(model, X, y, number_of_splits=100):\n",
    "    \n",
    "    yhat_tracker = pd.DataFrame({'ytrue':y})\n",
    "    \n",
    "    rowinds = list(range(X.shape[0]))\n",
    "    \n",
    "    for i in range(number_of_splits):\n",
    "        \n",
    "        train_inds, test_inds = train_test_split(rowinds, test_size=0.33)\n",
    "                \n",
    "        X_train, Y_train = X.iloc[train_inds, :], y[train_inds]\n",
    "        X_test, Y_test = X.iloc[test_inds, :], y[test_inds]\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "        yhats = model.predict(X_test)\n",
    "        \n",
    "        yhat_tracker['sample'+str(i+1)] = np.nan\n",
    "        yhat_tracker.iloc[test_inds, -1] = yhats\n",
    "        \n",
    "    return yhat_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different predictor datasets\n",
    "\n",
    "To see what happens to bias and variance as the predictors change, create a few versions of X that have different numbers of predictors in them:\n",
    "\n",
    "* model $X$ from above including all features\n",
    "* a model $X_{small}$ including only one feature (e.g. personal)\n",
    "* a model $X_{overfit}$ created with the patsy formula below \n",
    "    - taking the cube takes into account \n",
    "        - all original features\n",
    "        - all features that could be created by squaring or cubing a single column\n",
    "        - all products of two or three different columns\n",
    "        - all products of the squared of one column with a different column\n",
    "        - -1 excludes the intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overfit_formula = '~ ('+' + '.join(X.columns)+')**3 -1'\n",
    "#X_overfit = patsy.dmatrix(overfit_formula, data=X, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_small = X[['personal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the `predict_from_samples` function you wrote above to get the predicted values for $X$, $X_{small}$, $X_{overfit}$ \n",
    "\n",
    "- Run each of your X through the function with the y target vector. \n",
    "- Recall that the output of your function has the true values of y in one column and then predicted values of y for the different train-test splits in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate bias and variance \n",
    "\n",
    "Below are two functions to calculate bias and variance from the dataframe returned by your function `predict_from_samples`.\n",
    "You can use them to calculate the bias and variance for the models containing different feature combinations. \n",
    "\n",
    "If you have more predictors, variance of prediction should generally go up and bias go down. Likewise, if you have few predictors variance should go down and bias go up.\n",
    "\n",
    "For a bad model, they both might go up a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bias_sq(yhats_df):\n",
    "    # Take out the true values of y that are in the first column:\n",
    "    ytrue = yhats_df.iloc[:,0]\n",
    "    \n",
    "    # Calculate the mean of the predictions, averaged across the columns.\n",
    "    # So, all of the predictions for the true y at row 0 would be averaged together\n",
    "    # and so on for all the rows.\n",
    "    yhat_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # Subtract the true value of y from the mean of the predicted values, and square it.\n",
    "    elementwise_bias_sq = (yhat_means - ytrue)**2\n",
    "    \n",
    "    # Take the mean of those squared bias values (across all y)\n",
    "    mean_bias_sq = np.mean(elementwise_bias_sq)\n",
    "\n",
    "    return mean_bias_sq\n",
    "\n",
    "def calculate_variance(yhats_df):\n",
    "    \n",
    "    # Calculate the mean of the predicted y's across the columns (mean of yhat for each row)\n",
    "    yhats_means = yhats_df.iloc[:,1:].mean(axis=1)\n",
    "    \n",
    "    # subtract the mean of the yhats from the original yhat values (for each row)\n",
    "    # and square the result. \n",
    "    yhats_devsq = (yhats_df.iloc[:,1:].subtract(yhats_means, axis=0))**2\n",
    "    \n",
    "    # Take the mean of the squared deviations from the mean, then \n",
    "    # take the mean of those to get the overall variance across the y observations\n",
    "    yhats_devsq_means = yhats_devsq.mean(axis=1)\n",
    "    \n",
    "    return np.mean(yhats_devsq_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does regularization affect bias and variance?\n",
    "\n",
    "Use lasso and/or ridge regression on your dataset with all the predictor variables. In your function `predict_from_samples` replace `model` with your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso = Lasso(alpha=2.0)\n",
    "ridge = Ridge(alpha=2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
