{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practice Gridsearch and Multinomial Models with SF Crime Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Multinomial logistic regression models\n",
    "\n",
    "So far, we have been using logistic regression for binary problems where there are only two class labels. Logistic regression can be extended to dependent variables with multiple classes.\n",
    "\n",
    "There are two ways sklearn solves multiple-class problems with logistic regression: a multinomial loss or a \"one vs. rest\" (OvR) process where a model is fit for each target class vs. all the other classes. \n",
    "\n",
    "**Multinomial vs. OvR**\n",
    "- (M) 'k-1' models with 1 reference category\n",
    "- (OvR) 'k*(k-1)/2' models\n",
    "\n",
    "You will use the gridsearch in conjunction with multinomial logistic to optimize a model that predicts the category (type) of crime based on various features captured by San Francisco police departments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Necessary lab imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_csv = './datasets/sf_crime_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data using pandas\n",
    "sf_crime = pd.read_csv(crime_csv)\n",
    "sf_crime.drop('DayOfWeek',axis=1,inplace=True)\n",
    "sf_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of your dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whether there are any missing values\n",
    "#do we need to fix anything here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what your datatypes are\n",
    "#do we need to fix anything here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create column for year, month, day, hour, time, and date from 'Dates' column.\n",
    "\n",
    "> *`pd.to_datetime` and `Series.dt` may be helpful here!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'Dates' column to a datetime object\n",
    "sf_crime['Dates'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for 'Year','Month',and 'Day_of_Week'\n",
    "sf_crime['Year'] = sf_crime['Dates'].dt.year\n",
    "sf_crime['Month'] = \n",
    "sf_crime['Day_of_Week'] = \n",
    "#check the first couple rows to make sure it's what you want\n",
    "sf_crime.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column for the 'Hour','Time', and 'Date'\n",
    "sf_crime['Hour'] = \n",
    "sf_crime['Time'] = \n",
    "sf_crime['Date'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Dates' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validate and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the 'Category' value counts to see what sort of categories there are\n",
    "# and to see if anything might require cleaning (particularly the ones with fewer values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on with 'TRESPASS' and 'TRESPASSING'?\n",
    "# What's going on with 'ASSAULT' and 'ASSUALT'?\n",
    "# fix these with .loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look to see whether you have all the days of the week in your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the value counts for 'Descript', 'PdDistrict', and 'Resolution' to make sure it all checks out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .describe() to see whether the location coordinates seem appropriate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Set up a target and predictor matrix for predicting violent crime vs. non-violent crime vs. non-crimes.\n",
    "\n",
    "**Non-Violent Crimes:**\n",
    "- bad checks\n",
    "- bribery\n",
    "- drug/narcotic\n",
    "- drunkenness\n",
    "- embezzlement\n",
    "- forgery/counterfeiting\n",
    "- fraud\n",
    "- gambling\n",
    "- liquor\n",
    "- loitering \n",
    "- trespass\n",
    "\n",
    "**Non-Crimes:**\n",
    "- non-criminal\n",
    "- runaway\n",
    "- secondary codes\n",
    "- suspicious occ\n",
    "- warrants\n",
    "\n",
    "**Violent Crimes:**\n",
    "- everything else\n",
    "\n",
    "\n",
    "\n",
    "**What type of model do you need here? What is your baseline accuracy?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVC = ['BAD CHECKS','BRIBERY','DRUG/NARCOTIC','DRUNKENNESS',\n",
    "     'EMBEZZLEMENT','FORGERY/COUNTERFEITING','FRAUD',\n",
    "     'GAMBLING','LIQUOR','LOITERING','TRESPASS','OTHER OFFENSES']\n",
    "\n",
    "NOT_C = ['NON-CRIMINAL','RUNAWAY','SECONDARY CODES','SUSPICIOUS OCC','WARRANTS']\n",
    "\n",
    "#use a list comprehension to get all the categories in sf_crime['Category'].unique() that are NOT in the lists above\n",
    "\n",
    "VC = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column called 'Type' into your dataframe that stores whether the observation was:\n",
    "#Non-Violent, Violent, or Non-Crime\n",
    "#use .map()!\n",
    "def typecrime(x):\n",
    "    if x in NOT_C: return 'NOT_CRIMINAL'\n",
    "    if x in NVC: return 'NON-VIOLENT'\n",
    "    if x in VC: return 'VIOLENT_CRIME'\n",
    "\n",
    "sf_crime['Type']="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the baseline accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a target array with 'Type'\n",
    "#create a predictor matrix with 'Day_of_Week','Month','Year','PdDistrict','Hour', and 'Resolution'\n",
    "y = \n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pd.get_dummies() to dummify your categorical variables\n",
    "#remember to drop a column!\n",
    "X = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a train/test/split and standardize the predictor matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a 50/50 train test split; \n",
    "#stratify based on your target variable\n",
    "#use a random state of 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise your predictor matrices\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a basic Logistic Regression model and use cross_val_score to assess its performance on your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a default Logistic Regression model and find its mean cross-validated accuracy with your training data\n",
    "#use 5 cross-validation folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix with cross_val_predict\n",
    "predictions = cross_val_predict()\n",
    "confusion = confusion_matrix()\n",
    "pd.DataFrame(confusion,\n",
    "             columns=sorted(y_train.unique()),\n",
    "             index=sorted(y_train.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Find the optimal hyperparameters (optimal regularization) to predict your crime categories using GridSearchCV.\n",
    "\n",
    "> **Note:** Gridsearching can be done with `GridSearchCV` or `LogisticRegressionCV`. They operate differently - the gridsearch object is more general and can be applied to any model. The `LogisticRegressionCV` is specific to tuning the logistic regression hyperparameters. I recommend the logistic regression one, but the downside is that lasso and ridge must be searched separately. To start with, use `GridSearchCV`.\n",
    "\n",
    "**Reference for logistic regression regularization hyperparameters:**\n",
    "- `solver`: algorithm used for optimization (relevant for multiclass)\n",
    "    - Newton-cg - Handles Multinomial Loss, L2 only\n",
    "    - Sag - Handles Multinomial Loss, Large Datasets, L2 Only, Works best on scaled data\n",
    "    - lbfgs - Handles Multinomial Loss, L2 Only\n",
    "    - liblinear - Small Datasets, no Warm Starts\n",
    "- `C`: Regularization strengths (smaller values are stronger penalties)\n",
    "- `penalty`: `'l1'` - Lasso, `'l2'` - Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a hyperparameter dictionary for a logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a gridsearch object using LogisticRegression() and the dictionary you created above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the gridsearch object on your training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the best mean cross-validated score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign your best estimator to the variable 'best_logreg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score your model on your testing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Print out a classification report for your best_logreg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use your test data to create your classification report\n",
    "predictions = \n",
    "print(classification_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Explore LogisticRegressionCV.  \n",
    "\n",
    "With LogisticRegressionCV, you can access the best regularization strength for predicting each class! Read the documentation and see if you can implement a model with LogisticRegressionCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
